{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/grpo-dataset-v1/antlr4_python3_runtime-4.13.2-py3-none-any.whl\n",
      "Installing collected packages: antlr4-python3-runtime\n",
      "Successfully installed antlr4-python3-runtime-4.13.2\n",
      "Processing /kaggle/input/grpo-dataset-v1/av-14.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Installing collected packages: av\n",
      "Successfully installed av-14.4.0\n",
      "Processing /kaggle/input/grpo-dataset-v1/bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl\n",
      "Requirement already satisfied: torch<3,>=2.0 in /opt/conda/lib/python3.10/site-packages (from bitsandbytes==0.45.5) (2.4.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from bitsandbytes==0.45.5) (1.26.4)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes==0.45.5) (3.15.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes==0.45.5) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes==0.45.5) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes==0.45.5) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes==0.45.5) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes==0.45.5) (2024.6.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch<3,>=2.0->bitsandbytes==0.45.5) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch<3,>=2.0->bitsandbytes==0.45.5) (1.3.0)\n",
      "Installing collected packages: bitsandbytes\n",
      "Successfully installed bitsandbytes-0.45.5\n",
      "Processing /kaggle/input/grpo-dataset-v1/blake3-1.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Installing collected packages: blake3\n",
      "Successfully installed blake3-1.0.4\n",
      "Processing /kaggle/input/grpo-dataset-v1/hjson-3.1.0-py3-none-any.whl\n",
      "Installing collected packages: hjson\n",
      "Successfully installed hjson-3.1.0\n",
      "Processing /kaggle/input/grpo-dataset-v1/einops-0.8.1-py3-none-any.whl\n",
      "Installing collected packages: einops\n",
      "Successfully installed einops-0.8.1\n",
      "Processing /kaggle/input/grpo-dataset-v1/deepspeed-0.16.5-py3-none-any.whl\n",
      "Requirement already satisfied: einops in /opt/conda/lib/python3.10/site-packages (from deepspeed==0.16.5) (0.8.1)\n",
      "Requirement already satisfied: hjson in /opt/conda/lib/python3.10/site-packages (from deepspeed==0.16.5) (3.1.0)\n",
      "Requirement already satisfied: msgpack in /opt/conda/lib/python3.10/site-packages (from deepspeed==0.16.5) (1.0.8)\n",
      "Requirement already satisfied: ninja in /opt/conda/lib/python3.10/site-packages (from deepspeed==0.16.5) (1.11.1.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from deepspeed==0.16.5) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from deepspeed==0.16.5) (21.3)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from deepspeed==0.16.5) (5.9.3)\n",
      "Requirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.10/site-packages (from deepspeed==0.16.5) (9.0.0)\n",
      "Requirement already satisfied: pydantic>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from deepspeed==0.16.5) (2.9.2)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from deepspeed==0.16.5) (2.4.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from deepspeed==0.16.5) (4.66.4)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->deepspeed==0.16.5) (3.1.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.0.0->deepspeed==0.16.5) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.0.0->deepspeed==0.16.5) (2.23.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.0.0->deepspeed==0.16.5) (4.12.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->deepspeed==0.16.5) (3.15.1)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->deepspeed==0.16.5) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->deepspeed==0.16.5) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->deepspeed==0.16.5) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->deepspeed==0.16.5) (2024.6.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->deepspeed==0.16.5) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->deepspeed==0.16.5) (1.3.0)\n",
      "Installing collected packages: deepspeed\n",
      "Successfully installed deepspeed-0.16.5\n",
      "Processing /kaggle/input/grpo-dataset-v1/starlette-0.37.2-py3-none-any.whl\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /opt/conda/lib/python3.10/site-packages (from starlette==0.37.2) (4.4.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette==0.37.2) (3.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette==0.37.2) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette==0.37.2) (1.2.0)\n",
      "Requirement already satisfied: typing-extensions>=4.1 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette==0.37.2) (4.12.2)\n",
      "starlette is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n",
      "Processing /kaggle/input/grpo-dataset-v1/huggingface_hub-0.31.2-py3-none-any.whl\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub==0.31.2) (3.15.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub==0.31.2) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub==0.31.2) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub==0.31.2) (6.0.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub==0.31.2) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub==0.31.2) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub==0.31.2) (4.12.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub==0.31.2) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub==0.31.2) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub==0.31.2) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub==0.31.2) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub==0.31.2) (2024.8.30)\n",
      "Installing collected packages: huggingface-hub\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.25.1\n",
      "    Uninstalling huggingface-hub-0.25.1:\n",
      "      Successfully uninstalled huggingface-hub-0.25.1\n",
      "Successfully installed huggingface-hub-0.31.2\n",
      "Processing /kaggle/input/grpo-dataset-v1/tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/conda/lib/python3.10/site-packages (from tokenizers==0.21.1) (0.31.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.21.1) (3.15.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.21.1) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.21.1) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.21.1) (6.0.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.21.1) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.21.1) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.21.1) (4.12.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub<1.0,>=0.16.4->tokenizers==0.21.1) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers==0.21.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers==0.21.1) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers==0.21.1) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers==0.21.1) (2024.8.30)\n",
      "Installing collected packages: tokenizers\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.20.0\n",
      "    Uninstalling tokenizers-0.20.0:\n",
      "      Successfully uninstalled tokenizers-0.20.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "transformers 4.45.1 requires tokenizers<0.21,>=0.20, but you have tokenizers 0.21.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed tokenizers-0.21.1\n",
      "Processing /kaggle/input/grpo-dataset-v1/transformers-4.51.3-py3-none-any.whl\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.51.3) (3.15.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.51.3) (0.31.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.51.3) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.51.3) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.51.3) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.51.3) (2024.5.15)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.51.3) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.10/site-packages (from transformers==4.51.3) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.10/site-packages (from transformers==4.51.3) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.51.3) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.51.3) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.51.3) (4.12.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers==4.51.3) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.51.3) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.51.3) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.51.3) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.51.3) (2024.8.30)\n",
      "Installing collected packages: transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.45.1\n",
      "    Uninstalling transformers-4.45.1:\n",
      "      Successfully uninstalled transformers-4.45.1\n",
      "Successfully installed transformers-4.51.3\n",
      "Processing /kaggle/input/grpo-dataset-v1/compressed_tensors-0.9.3-py3-none-any.whl\n",
      "Requirement already satisfied: torch>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from compressed-tensors==0.9.3) (2.4.0)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from compressed-tensors==0.9.3) (4.51.3)\n",
      "Requirement already satisfied: pydantic>=2.0 in /opt/conda/lib/python3.10/site-packages (from compressed-tensors==0.9.3) (2.9.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.0->compressed-tensors==0.9.3) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.0->compressed-tensors==0.9.3) (2.23.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.0->compressed-tensors==0.9.3) (4.12.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.0->compressed-tensors==0.9.3) (3.15.1)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.0->compressed-tensors==0.9.3) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.0->compressed-tensors==0.9.3) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.0->compressed-tensors==0.9.3) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.0->compressed-tensors==0.9.3) (2024.6.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /opt/conda/lib/python3.10/site-packages (from transformers->compressed-tensors==0.9.3) (0.31.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers->compressed-tensors==0.9.3) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers->compressed-tensors==0.9.3) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers->compressed-tensors==0.9.3) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->compressed-tensors==0.9.3) (2024.5.15)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers->compressed-tensors==0.9.3) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.10/site-packages (from transformers->compressed-tensors==0.9.3) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.10/site-packages (from transformers->compressed-tensors==0.9.3) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers->compressed-tensors==0.9.3) (4.66.4)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers->compressed-tensors==0.9.3) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.7.0->compressed-tensors==0.9.3) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->compressed-tensors==0.9.3) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->compressed-tensors==0.9.3) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->compressed-tensors==0.9.3) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->compressed-tensors==0.9.3) (2024.8.30)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.7.0->compressed-tensors==0.9.3) (1.3.0)\n",
      "Installing collected packages: compressed-tensors\n",
      "Successfully installed compressed-tensors-0.9.3\n",
      "Processing /kaggle/input/grpo-dataset-v1/filelock-3.18.0-py3-none-any.whl\n",
      "Installing collected packages: filelock\n",
      "  Attempting uninstall: filelock\n",
      "    Found existing installation: filelock 3.15.1\n",
      "    Uninstalling filelock-3.15.1:\n",
      "      Successfully uninstalled filelock-3.15.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "ibis-framework 7.1.0 requires pyarrow<15,>=2, but you have pyarrow 16.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed filelock-3.18.0\n",
      "\u001b[31mERROR: flash_attn-2.7.42Bcu124torch2.6.0cxx11abiFALSE-cp312-cp312-win_amd64.whl is not a supported wheel on this platform.\u001b[0m\u001b[31m\n",
      "\u001b[0mProcessing /kaggle/input/grpo-dataset-v1/hf_xet-1.1.2-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Installing collected packages: hf-xet\n",
      "Successfully installed hf-xet-1.1.2\n",
      "Processing /kaggle/input/grpo-dataset-v1/jinja2-3.1.6-py3-none-any.whl\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2==3.1.6) (2.1.5)\n",
      "Installing collected packages: jinja2\n",
      "  Attempting uninstall: jinja2\n",
      "    Found existing installation: Jinja2 3.1.4\n",
      "    Uninstalling Jinja2-3.1.4:\n",
      "      Successfully uninstalled Jinja2-3.1.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "beatrix-jupyterlab 2024.66.154055 requires jupyterlab~=3.6.0, but you have jupyterlab 4.2.5 which is incompatible.\n",
      "distributed 2024.7.1 requires dask==2024.7.1, but you have dask 2024.9.1 which is incompatible.\n",
      "jupyterlab 4.2.5 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\n",
      "jupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\n",
      "rapids-dask-dependency 24.8.0a0 requires dask==2024.7.1, but you have dask 2024.9.1 which is incompatible.\n",
      "ydata-profiling 4.10.0 requires scipy<1.14,>=1.4.1, but you have scipy 1.14.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed jinja2-3.1.6\n",
      "Processing /kaggle/input/grpo-dataset-v1/latex2sympy2_extended-1.10.1-py3-none-any.whl\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from latex2sympy2-extended==1.10.1) (1.13.3)\n",
      "Requirement already satisfied: antlr4-python3-runtime<=4.13.2,>=4.9.3 in /opt/conda/lib/python3.10/site-packages (from latex2sympy2-extended==1.10.1) (4.13.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->latex2sympy2-extended==1.10.1) (1.3.0)\n",
      "Installing collected packages: latex2sympy2-extended\n",
      "Successfully installed latex2sympy2-extended-1.10.1\n",
      "Processing /kaggle/input/grpo-dataset-v1/math_verify-0.7.0-py3-none-any.whl\n",
      "Requirement already satisfied: latex2sympy2_extended==1.10.1 in /opt/conda/lib/python3.10/site-packages (from math-verify==0.7.0) (1.10.1)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from latex2sympy2_extended==1.10.1->math-verify==0.7.0) (1.13.3)\n",
      "Requirement already satisfied: antlr4-python3-runtime<=4.13.2,>=4.9.3 in /opt/conda/lib/python3.10/site-packages (from latex2sympy2_extended==1.10.1->math-verify==0.7.0) (4.13.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->latex2sympy2_extended==1.10.1->math-verify==0.7.0) (1.3.0)\n",
      "Installing collected packages: math-verify\n",
      "Successfully installed math-verify-0.7.0\n",
      "\u001b[31mERROR: opencv_python_headless-4.11.0.86-cp37-abi3-macosx_13_0_x86_64.whl is not a supported wheel on this platform.\u001b[0m\u001b[31m\n",
      "\u001b[0mProcessing /kaggle/input/grpo-dataset-v1/partial_json_parser-0.2.1.1.post5-py3-none-any.whl\n",
      "Installing collected packages: partial-json-parser\n",
      "Successfully installed partial-json-parser-0.2.1.1.post5\n",
      "Processing /kaggle/input/grpo-dataset-v1/fastapi-0.112.0-py3-none-any.whl\n",
      "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /opt/conda/lib/python3.10/site-packages (from fastapi==0.112.0) (0.37.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from fastapi==0.112.0) (2.9.2)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from fastapi==0.112.0) (4.12.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi==0.112.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi==0.112.0) (2.23.4)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /opt/conda/lib/python3.10/site-packages (from starlette<0.38.0,>=0.37.2->fastapi==0.112.0) (4.4.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette<0.38.0,>=0.37.2->fastapi==0.112.0) (3.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette<0.38.0,>=0.37.2->fastapi==0.112.0) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette<0.38.0,>=0.37.2->fastapi==0.112.0) (1.2.0)\n",
      "Installing collected packages: fastapi\n",
      "  Attempting uninstall: fastapi\n",
      "    Found existing installation: fastapi 0.111.0\n",
      "    Uninstalling fastapi-0.111.0:\n",
      "      Successfully uninstalled fastapi-0.111.0\n",
      "Successfully installed fastapi-0.112.0\n",
      "Processing /kaggle/input/grpo-dataset-v1/vllm-0.8.0-cp38-abi3-manylinux1_x86_64.whl\n",
      "Requirement already satisfied: cachetools in /opt/conda/lib/python3.10/site-packages (from vllm==0.8.0) (4.2.4)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from vllm==0.8.0) (5.9.3)\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from vllm==0.8.0) (0.2.0)\n",
      "Requirement already satisfied: numpy<2.0.0 in /opt/conda/lib/python3.10/site-packages (from vllm==0.8.0) (1.26.4)\n",
      "Requirement already satisfied: requests>=2.26.0 in /opt/conda/lib/python3.10/site-packages (from vllm==0.8.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from vllm==0.8.0) (4.66.4)\n",
      "Requirement already satisfied: blake3 in /opt/conda/lib/python3.10/site-packages (from vllm==0.8.0) (1.0.4)\n",
      "Requirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.10/site-packages (from vllm==0.8.0) (9.0.0)\n",
      "Requirement already satisfied: transformers>=4.48.2 in /opt/conda/lib/python3.10/site-packages (from vllm==0.8.0) (4.51.3)\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in /opt/conda/lib/python3.10/site-packages (from vllm==0.8.0) (0.21.1)\n",
      "Requirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from vllm==0.8.0) (3.20.3)\n",
      "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7bdf67398250>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/fastapi/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7bdf6738b430>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/fastapi/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7bdf6738af50>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/fastapi/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7bdf673895a0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/fastapi/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7bdf67389540>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/fastapi/\u001b[0m\u001b[33m\n",
      "\u001b[0mINFO: pip is looking at multiple versions of vllm to determine which version is compatible with other requirements. This could take a while.\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement fastapi>=0.115.0 (from vllm) (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for fastapi>=0.115.0\u001b[0m\u001b[31m\n",
      "\u001b[0mProcessing /kaggle/input/grpo-dataset-v1/peft-0.15.2-py3-none-any.whl\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft==0.15.2) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.15.2) (21.3)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft==0.15.2) (5.9.3)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft==0.15.2) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.15.2) (2.4.0)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft==0.15.2) (4.51.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft==0.15.2) (4.66.4)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.15.2) (0.34.2)\n",
      "Requirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft==0.15.2) (0.4.5)\n",
      "Requirement already satisfied: huggingface_hub>=0.25.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.15.2) (0.31.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface_hub>=0.25.0->peft==0.15.2) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub>=0.25.0->peft==0.15.2) (2024.6.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface_hub>=0.25.0->peft==0.15.2) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub>=0.25.0->peft==0.15.2) (4.12.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft==0.15.2) (3.1.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.15.2) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.15.2) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.15.2) (3.1.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft==0.15.2) (2024.5.15)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.10/site-packages (from transformers->peft==0.15.2) (0.21.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft==0.15.2) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub>=0.25.0->peft==0.15.2) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub>=0.25.0->peft==0.15.2) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub>=0.25.0->peft==0.15.2) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub>=0.25.0->peft==0.15.2) (2024.8.30)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft==0.15.2) (1.3.0)\n",
      "Installing collected packages: peft\n",
      "Successfully installed peft-0.15.2\n",
      "Processing /kaggle/input/grpo-dataset-v1/python_multipart-0.0.20-py3-none-any.whl\n",
      "Installing collected packages: python-multipart\n",
      "  Attempting uninstall: python-multipart\n",
      "    Found existing installation: python-multipart 0.0.9\n",
      "    Uninstalling python-multipart-0.0.9:\n",
      "      Successfully uninstalled python-multipart-0.0.9\n",
      "Successfully installed python-multipart-0.0.20\n",
      "Processing /kaggle/input/grpo-dataset-v1/qwen_vl_utils-0.0.11-py3-none-any.whl\n",
      "Requirement already satisfied: av in /opt/conda/lib/python3.10/site-packages (from qwen-vl-utils==0.0.11) (14.4.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from qwen-vl-utils==0.0.11) (21.3)\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (from qwen-vl-utils==0.0.11) (10.3.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from qwen-vl-utils==0.0.11) (2.32.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->qwen-vl-utils==0.0.11) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->qwen-vl-utils==0.0.11) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->qwen-vl-utils==0.0.11) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->qwen-vl-utils==0.0.11) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->qwen-vl-utils==0.0.11) (2024.8.30)\n",
      "Installing collected packages: qwen-vl-utils\n",
      "Successfully installed qwen-vl-utils-0.0.11\n",
      "Processing /kaggle/input/grpo-dataset-v1/ray-2.46.0-cp310-cp310-manylinux2014_x86_64.whl\n",
      "Requirement already satisfied: click>=7.0 in /opt/conda/lib/python3.10/site-packages (from ray==2.46.0) (8.1.7)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from ray==2.46.0) (3.18.0)\n",
      "Requirement already satisfied: jsonschema in /opt/conda/lib/python3.10/site-packages (from ray==2.46.0) (4.22.0)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from ray==2.46.0) (1.0.8)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from ray==2.46.0) (21.3)\n",
      "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /opt/conda/lib/python3.10/site-packages (from ray==2.46.0) (3.20.3)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from ray==2.46.0) (6.0.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from ray==2.46.0) (2.32.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema->ray==2.46.0) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema->ray==2.46.0) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema->ray==2.46.0) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema->ray==2.46.0) (0.18.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->ray==2.46.0) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->ray==2.46.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->ray==2.46.0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->ray==2.46.0) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->ray==2.46.0) (2024.8.30)\n",
      "Installing collected packages: ray\n",
      "  Attempting uninstall: ray\n",
      "    Found existing installation: ray 2.24.0\n",
      "    Uninstalling ray-2.24.0:\n",
      "      Successfully uninstalled ray-2.24.0\n",
      "Successfully installed ray-2.46.0\n",
      "Processing /kaggle/input/grpo-dataset-v1/rich_toolkit-0.14.6-py3-none-any.whl\n",
      "Requirement already satisfied: click>=8.1.7 in /opt/conda/lib/python3.10/site-packages (from rich-toolkit==0.14.6) (8.1.7)\n",
      "Requirement already satisfied: rich>=13.7.1 in /opt/conda/lib/python3.10/site-packages (from rich-toolkit==0.14.6) (13.7.1)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /opt/conda/lib/python3.10/site-packages (from rich-toolkit==0.14.6) (4.12.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=13.7.1->rich-toolkit==0.14.6) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=13.7.1->rich-toolkit==0.14.6) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=13.7.1->rich-toolkit==0.14.6) (0.1.2)\n",
      "Installing collected packages: rich-toolkit\n",
      "Successfully installed rich-toolkit-0.14.6\n",
      "Processing /kaggle/input/grpo-dataset-v1/sympy-1.13.1-py3-none-any.whl\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy==1.13.1) (1.3.0)\n",
      "Installing collected packages: sympy\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.13.3\n",
      "    Uninstalling sympy-1.13.3:\n",
      "      Successfully uninstalled sympy-1.13.3\n",
      "Successfully installed sympy-1.13.1\n",
      "Processing /kaggle/input/grpo-dataset-v1/torchao-0.11.0-cp39-abi3-manylinux_2_28_x86_64.manylinux_2_24_x86_64.whl\n",
      "Installing collected packages: torchao\n",
      "Successfully installed torchao-0.11.0\n",
      "Processing /kaggle/input/grpo-dataset-v1/triton-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Installing collected packages: triton\n",
      "Successfully installed triton-3.2.0\n",
      "Processing /kaggle/input/grpo-dataset-v1/trl-0.17.0-py3-none-any.whl\n",
      "Requirement already satisfied: accelerate>=0.34.0 in /opt/conda/lib/python3.10/site-packages (from trl==0.17.0) (0.34.2)\n",
      "Requirement already satisfied: datasets>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from trl==0.17.0) (3.0.1)\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from trl==0.17.0) (13.7.1)\n",
      "Requirement already satisfied: transformers>=4.46.0 in /opt/conda/lib/python3.10/site-packages (from trl==0.17.0) (4.51.3)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.34.0->trl==0.17.0) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.34.0->trl==0.17.0) (21.3)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.34.0->trl==0.17.0) (5.9.3)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.34.0->trl==0.17.0) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.34.0->trl==0.17.0) (2.4.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.34.0->trl==0.17.0) (0.31.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.34.0->trl==0.17.0) (0.4.5)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=3.0.0->trl==0.17.0) (3.18.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=3.0.0->trl==0.17.0) (16.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=3.0.0->trl==0.17.0) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets>=3.0.0->trl==0.17.0) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets>=3.0.0->trl==0.17.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.10/site-packages (from datasets>=3.0.0->trl==0.17.0) (4.66.4)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets>=3.0.0->trl==0.17.0) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets>=3.0.0->trl==0.17.0) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets>=3.0.0->trl==0.17.0) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=3.0.0->trl==0.17.0) (3.9.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.46.0->trl==0.17.0) (2024.5.15)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.46.0->trl==0.17.0) (0.21.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->trl==0.17.0) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->trl==0.17.0) (2.18.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=3.0.0->trl==0.17.0) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=3.0.0->trl==0.17.0) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=3.0.0->trl==0.17.0) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=3.0.0->trl==0.17.0) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=3.0.0->trl==0.17.0) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=3.0.0->trl==0.17.0) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.34.0->trl==0.17.0) (4.12.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->trl==0.17.0) (0.1.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate>=0.34.0->trl==0.17.0) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=3.0.0->trl==0.17.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=3.0.0->trl==0.17.0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=3.0.0->trl==0.17.0) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=3.0.0->trl==0.17.0) (2024.8.30)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.34.0->trl==0.17.0) (1.13.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.34.0->trl==0.17.0) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.34.0->trl==0.17.0) (3.1.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets>=3.0.0->trl==0.17.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets>=3.0.0->trl==0.17.0) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets>=3.0.0->trl==0.17.0) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.0.0->trl==0.17.0) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate>=0.34.0->trl==0.17.0) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate>=0.34.0->trl==0.17.0) (1.3.0)\n",
      "Installing collected packages: trl\n",
      "Successfully installed trl-0.17.0\n",
      "Processing /kaggle/input/grpo-dataset-v1/numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "cudf 24.8.3 requires cubinlinker, which is not installed.\n",
      "cudf 24.8.3 requires cupy-cuda11x>=12.0.0, which is not installed.\n",
      "cudf 24.8.3 requires ptxcompiler, which is not installed.\n",
      "cuml 24.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\n",
      "dask-cudf 24.8.3 requires cupy-cuda11x>=12.0.0, which is not installed.\n",
      "ucxx 0.39.1 requires libucx>=1.15.0, which is not installed.\n",
      "apache-beam 2.46.0 requires cloudpickle~=2.2.1, but you have cloudpickle 3.0.0 which is incompatible.\n",
      "apache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\n",
      "apache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\n",
      "apache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 16.1.0 which is incompatible.\n",
      "cesium 0.12.3 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "cudf 24.8.3 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.6.0 which is incompatible.\n",
      "gensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.14.1 which is incompatible.\n",
      "ibis-framework 7.1.0 requires pyarrow<15,>=2, but you have pyarrow 16.1.0 which is incompatible.\n",
      "libpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\n",
      "libpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\n",
      "rmm 24.8.2 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.6.0 which is incompatible.\n",
      "xarray 2024.9.0 requires packaging>=23.1, but you have packaging 21.3 which is incompatible.\n",
      "ydata-profiling 4.10.0 requires scipy<1.14,>=1.4.1, but you have scipy 1.14.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-1.26.4\n",
      "Processing /kaggle/input/grpo-dataset-v1/filelock-3.18.0-py3-none-any.whl\n",
      "filelock is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n",
      "Processing /kaggle/input/grpo-dataset-v1/optree-0.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /opt/conda/lib/python3.10/site-packages (from optree==0.14.0) (4.12.2)\n",
      "Installing collected packages: optree\n",
      "  Attempting uninstall: optree\n",
      "    Found existing installation: optree 0.11.0\n",
      "    Uninstalling optree-0.11.0:\n",
      "      Successfully uninstalled optree-0.11.0\n",
      "Successfully installed optree-0.14.0\n",
      "Processing /kaggle/input/grpo-dataset-v1/nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl\n",
      "Installing collected packages: nvidia-cuda-nvrtc-cu12\n",
      "Successfully installed nvidia-cuda-nvrtc-cu12-12.4.127\n",
      "Processing /kaggle/input/grpo-dataset-v1/torch-2.6.0-cp310-cp310-manylinux1_x86_64.whl\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch==2.6.0) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/conda/lib/python3.10/site-packages (from torch==2.6.0) (4.12.2)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.6.0) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch==2.6.0) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch==2.6.0) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.10/site-packages (from torch==2.6.0) (12.4.127)\n",
      "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7d793ea8a890>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/nvidia-cuda-runtime-cu12/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7d793ea8a140>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/nvidia-cuda-runtime-cu12/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7d793ea88be0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/nvidia-cuda-runtime-cu12/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7d793ea8b3a0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/nvidia-cuda-runtime-cu12/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7d793ea8b580>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/nvidia-cuda-runtime-cu12/\u001b[0m\u001b[33m\n",
      "\u001b[0mINFO: pip is looking at multiple versions of torch to determine which version is compatible with other requirements. This could take a while.\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\" (from torch) (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\"\u001b[0m\u001b[31m\n",
      "\u001b[0mProcessing /kaggle/input/grpo-dataset-v1/torchvision-0.21.0-cp310-cp310-manylinux1_x86_64.whl\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision==0.21.0) (1.26.4)\n",
      "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7b594130ded0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/torch/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7b594130e080>: Failed to establish a new connection: [Errno -2] Name or service not known')': /simple/torch/\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting torch==2.6.0 (from torchvision==0.21.0)\n",
      "  Downloading torch-2.6.0-cp310-cp310-manylinux1_x86_64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision==0.21.0) (10.3.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch==2.6.0->torchvision==0.21.0) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/conda/lib/python3.10/site-packages (from torch==2.6.0->torchvision==0.21.0) (4.12.2)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.6.0->torchvision==0.21.0) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch==2.6.0->torchvision==0.21.0) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch==2.6.0->torchvision==0.21.0) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.10/site-packages (from torch==2.6.0->torchvision==0.21.0) (12.4.127)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.6.0->torchvision==0.21.0)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.6.0->torchvision==0.21.0)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.6.0->torchvision==0.21.0)\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.6.0->torchvision==0.21.0)\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.6.0->torchvision==0.21.0)\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch==2.6.0->torchvision==0.21.0)\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.6.0->torchvision==0.21.0)\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.6.0->torchvision==0.21.0)\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.6.2 (from torch==2.6.0->torchvision==0.21.0)\n",
      "  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting nvidia-nccl-cu12==2.21.5 (from torch==2.6.0->torchvision==0.21.0)\n",
      "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.4.127 (from torch==2.6.0->torchvision==0.21.0)\n",
      "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.6.0->torchvision==0.21.0)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: triton==3.2.0 in /opt/conda/lib/python3.10/site-packages (from torch==2.6.0->torchvision==0.21.0) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.10/site-packages (from torch==2.6.0->torchvision==0.21.0) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy==1.13.1->torch==2.6.0->torchvision==0.21.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch==2.6.0->torchvision==0.21.0) (2.1.5)\n",
      "Downloading torch-2.6.0-cp310-cp310-manylinux1_x86_64.whl (766.7 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m766.7/766.7 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m121.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m42.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m101.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-cusparselt-cu12, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.4.0\n",
      "    Uninstalling torch-2.4.0:\n",
      "      Successfully uninstalled torch-2.4.0\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.19.0\n",
      "    Uninstalling torchvision-0.19.0:\n",
      "      Successfully uninstalled torchvision-0.19.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "fastai 2.7.17 requires torch<2.5,>=1.10, but you have torch 2.6.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 torch-2.6.0 torchvision-0.21.0\n"
     ]
    }
   ],
   "source": [
    "!pip install /kaggle/input/grpo-dataset-v1/antlr4_python3_runtime-4.13.2-py3-none-any.whl  \n",
    "!pip install /kaggle/input/grpo-dataset-v1/av-14.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl \n",
    "!pip install /kaggle/input/grpo-dataset-v1/bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl \n",
    "!pip install /kaggle/input/grpo-dataset-v1/blake3-1.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl \n",
    "!pip install /kaggle/input/grpo-dataset-v1/hjson-3.1.0-py3-none-any.whl \n",
    "!pip install /kaggle/input/grpo-dataset-v1/einops-0.8.1-py3-none-any.whl \n",
    "!pip install /kaggle/input/grpo-dataset-v1/deepspeed-0.16.5-py3-none-any.whl \n",
    "!pip install /kaggle/input/grpo-dataset-v1/starlette-0.37.2-py3-none-any.whl \n",
    "!pip install /kaggle/input/grpo-dataset-v1/huggingface_hub-0.31.2-py3-none-any.whl\n",
    "!pip install /kaggle/input/grpo-dataset-v1/tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl \n",
    "!pip install /kaggle/input/grpo-dataset-v1/transformers-4.51.3-py3-none-any.whl \n",
    "!pip install /kaggle/input/grpo-dataset-v1/compressed_tensors-0.9.3-py3-none-any.whl \n",
    "!pip install /kaggle/input/grpo-dataset-v1/filelock-3.18.0-py3-none-any.whl \n",
    "!pip install /kaggle/input/grpo-dataset-v1/flash_attn-2.7.42Bcu124torch2.6.0cxx11abiFALSE-cp312-cp312-win_amd64.whl \n",
    "!pip install /kaggle/input/grpo-dataset-v1/hf_xet-1.1.2-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl \n",
    "!pip install /kaggle/input/grpo-dataset-v1/jinja2-3.1.6-py3-none-any.whl \n",
    "!pip install /kaggle/input/grpo-dataset-v1/latex2sympy2_extended-1.10.1-py3-none-any.whl \n",
    "!pip install /kaggle/input/grpo-dataset-v1/math_verify-0.7.0-py3-none-any.whl \n",
    "!pip install /kaggle/input/grpo-dataset-v1/opencv_python_headless-4.11.0.86-cp37-abi3-macosx_13_0_x86_64.whl \n",
    "!pip install /kaggle/input/grpo-dataset-v1/partial_json_parser-0.2.1.1.post5-py3-none-any.whl\n",
    "!pip install /kaggle/input/grpo-dataset-v1/fastapi-0.112.0-py3-none-any.whl\n",
    "!pip install /kaggle/input/grpo-dataset-v1/vllm-0.8.0-cp38-abi3-manylinux1_x86_64.whl\n",
    "!pip install /kaggle/input/grpo-dataset-v1/peft-0.15.2-py3-none-any.whl \n",
    "!pip install /kaggle/input/grpo-dataset-v1/python_multipart-0.0.20-py3-none-any.whl \n",
    "!pip install /kaggle/input/grpo-dataset-v1/qwen_vl_utils-0.0.11-py3-none-any.whl \n",
    "!pip install /kaggle/input/grpo-dataset-v1/ray-2.46.0-cp310-cp310-manylinux2014_x86_64.whl \n",
    "!pip install /kaggle/input/grpo-dataset-v1/rich_toolkit-0.14.6-py3-none-any.whl \n",
    "!pip install /kaggle/input/grpo-dataset-v1/sympy-1.13.1-py3-none-any.whl \n",
    "!pip install /kaggle/input/grpo-dataset-v1/torchao-0.11.0-cp39-abi3-manylinux_2_28_x86_64.manylinux_2_24_x86_64.whl \n",
    "!pip install /kaggle/input/grpo-dataset-v1/triton-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl \n",
    "!pip install /kaggle/input/grpo-dataset-v1/trl-0.17.0-py3-none-any.whl \n",
    "!pip install /kaggle/input/grpo-dataset-v1/numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl --force-reinstall\n",
    "!pip install /kaggle/input/grpo-dataset-v1/filelock-3.18.0-py3-none-any.whl\n",
    "!pip install /kaggle/input/grpo-dataset-v1/optree-0.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
    "!pip install /kaggle/input/grpo-dataset-v1/nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl --force-reinstall\n",
    "!pip install /kaggle/input/grpo-dataset-v1/torch-2.6.0-cp310-cp310-manylinux1_x86_64.whl\n",
    "!pip install /kaggle/input/grpo-dataset-v1/torchvision-0.21.0-cp310-cp310-manylinux1_x86_64.whl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install /kaggle/input/grpo-dataset-v1/nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl --force-reinstall\n",
    "!pip install /kaggle/input/grpo-dataset-v1/torch-2.6.0-cp310-cp310-manylinux1_x86_64.whl\n",
    "!pip install /kaggle/input/grpo-dataset-v1/torchvision-0.21.0-cp310-cp310-manylinux1_x86_64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"48\"\n",
    "wandb.login(key=\"02ba155e26496a78f062f683274330566fefe94c\")\n",
    "\n",
    "# # !git pull\n",
    "# !bash scripts/run_grpo_video.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'TimeZero'...\n",
      "remote: Enumerating objects: 872, done.\u001b[K\n",
      "remote: Counting objects: 100% (6/6), done.\u001b[K\n",
      "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
      "remote: Total 872 (delta 0), reused 2 (delta 0), pack-reused 866 (from 1)\u001b[K\n",
      "Receiving objects: 100% (872/872), 4.15 MiB | 22.95 MiB/s, done.\n",
      "Resolving deltas: 100% (542/542), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/tnt305/TimeZero.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'TimeZero'\n",
      "/kaggle/working/TimeZero\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up to date.\n"
     ]
    }
   ],
   "source": [
    "%cd TimeZero\n",
    "!git pull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.34.2)\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-1.7.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.6.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.31.4)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.10/site-packages (from accelerate) (0.4.5)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (2024.6.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
      "Requirement already satisfied: triton==3.2.0 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.10/site-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=2.0.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2024.8.30)\n",
      "Downloading accelerate-1.7.0-py3-none-any.whl (362 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m362.1/362.1 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h\u001b[33mWARNING: Error parsing requirements for numba: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/numba-0.60.0.dist-info/METADATA'\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: accelerate\n",
      "  Attempting uninstall: accelerate\n",
      "    Found existing installation: accelerate 0.34.2\n",
      "    Uninstalling accelerate-0.34.2:\n",
      "      Successfully uninstalled accelerate-0.34.2\n",
      "Successfully installed accelerate-1.7.0\n"
     ]
    }
   ],
   "source": [
    "# !pip install qwen-vl-utils bitsandbytes transformers math-verify trl[vllm] datasets peft hf-xet\n",
    "# !pip install --upgrade autoawq\n",
    "# !pip install torch==2.6.0 torchvision==0.21.0\n",
    "# !pip install --upgrade accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoProcessor\n",
    "from qwen_vl_utils import process_vision_info\n",
    "input_file = \"/kaggle/input/grpo-dataset/unique_videos.jsonl\"\n",
    "MODEL_NAME = \"unsloth/Qwen2.5-VL-3B-Instruct-unsloth-bnb-4bit\"\n",
    "\n",
    "\n",
    "def get_duration(video_path):\n",
    "    if not os.path.exists(video_path):\n",
    "        # raise FileNotFoundError(f\"Video file not found: {video_path}\")\n",
    "        print(f\"Video file not found: {video_path}\")\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        raise RuntimeError(f\"Failed to open video: {video_path}\")\n",
    "\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_count = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    cap.release()\n",
    "\n",
    "    if fps > 0:\n",
    "        duration = frame_count / fps\n",
    "    else:\n",
    "        duration = 0\n",
    "\n",
    "    return duration\n",
    "\n",
    "\n",
    "def preprocess_video_inner(video_path, processor, max_pixels, min_pixels):\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": [\n",
    "                {\"type\": \"video\",\n",
    "                \"video\": video_path,\n",
    "                \"total_pixels\": max_pixels,\n",
    "                \"min_pixels\": min_pixels,\n",
    "                },\n",
    "            ]\n",
    "        },\n",
    "    ]\n",
    "    image_inputs, video_inputs, video_kwargs = process_vision_info([messages], return_video_kwargs=True)\n",
    "    fps_inputs = video_kwargs['fps']\n",
    "    return image_inputs, video_inputs, video_kwargs, fps_inputs\n",
    "\n",
    "def process_single_video(task_args):\n",
    "    video_path, processor, max_pixels, min_pixels, example_output_dir, sentence, solution, duration = task_args\n",
    "    image_inputs, video_inputs, video_kwargs, fps_inputs = preprocess_video_inner(video_path, processor, max_pixels, min_pixels)\n",
    "\n",
    "\n",
    "    example_output_dir = video_path.split(\"/\")[-1].split(\".\")[0]\n",
    "    example_output_dir = f\"./dataset/train/{example_output_dir}\"\n",
    "    os.makedirs(example_output_dir, exist_ok=True)\n",
    "    torch.save(video_inputs, os.path.join(example_output_dir, \"video_inputs.pt\"))\n",
    "    with open(os.path.join(example_output_dir, \"video_kwargs.json\"), 'w') as f:\n",
    "        json.dump(video_kwargs, f)\n",
    "\n",
    "    return {\n",
    "            \"problem\": sentence,\n",
    "            \"solution\": solution,\n",
    "            \"preprocessed_path\": example_output_dir,\n",
    "            \"duration\": duration,\n",
    "            \"status\": \"success\"\n",
    "        }\n",
    "\n",
    "\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = [json.loads(line) for line in f if line.strip()]\n",
    "\n",
    "def process_split(file_path, split_name, output_dir, max_pixels, min_pixels, processor):\n",
    "    processor = AutoProcessor.from_pretrained(MODEL_NAME)\n",
    "\n",
    "    output_split_dir = os.path.join(output_dir, split_name)\n",
    "    os.makedirs(output_split_dir, exist_ok=True)\n",
    "\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = [json.loads(line.strip()) for line in f]\n",
    "    data = data[: 10]\n",
    "    examples = []\n",
    "    tasks = []\n",
    "\n",
    "    for video in tqdm(data):\n",
    "        timestamps = video[\"timestamp\"]\n",
    "        sentence = video[\"caption\"].strip().lower()\n",
    "        if sentence.endswith(\".\"):\n",
    "            sentence = sentence[:-1]\n",
    "\n",
    "        video_path = video[\"video\"]\n",
    "        video_id = video_path.split(\"/\")[-1].split(\".\")[0]\n",
    "\n",
    "        example_output_dir = os.path.join(output_split_dir, f\"{video_id}\")\n",
    "        duration = get_duration(video[\"video\"])\n",
    "        solution = (float(timestamps[0]) / duration, float(timestamps[1]) / duration)\n",
    "\n",
    "        tasks.append((video_path, processor, max_pixels, min_pixels, example_output_dir, sentence, solution, duration))\n",
    "    print(\"task has ended\")\n",
    "    return tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optree in /opt/conda/lib/python3.10/site-packages (0.11.0)\n",
      "Collecting optree\n",
      "  Downloading optree-0.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4.5.0 in /opt/conda/lib/python3.10/site-packages (from optree) (4.12.2)\n",
      "Downloading optree-0.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (397 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m397.1/397.1 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h\u001b[33mWARNING: Error parsing requirements for numba: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/numba-0.60.0.dist-info/METADATA'\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: optree\n",
      "  Attempting uninstall: optree\n",
      "    Found existing installation: optree 0.11.0\n",
      "    Uninstalling optree-0.11.0:\n",
      "      Successfully uninstalled optree-0.11.0\n",
      "Successfully installed optree-0.15.0\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade optree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "\n",
    "with open(\"/kaggle/input/grpo-dataset/unique_videos.jsonl\", \"r\") as f:\n",
    "    data = [json.loads(line) for line in f]\n",
    "\n",
    "for item in data:\n",
    "    if 'video' in item:\n",
    "        item['video'] = item['video'].replace(\"D:/sub_sys/data_grpo/\", \"/kaggle/input/grpo-dataset/data_grpo/\")\n",
    "\n",
    "with open(\"unique_videos.jsonl\", \"w\") as f:\n",
    "    for item in data:\n",
    "        f.write(json.dumps(item) + \"\\n\")\n",
    "with open(\"train.jsonl\", \"w\") as f:\n",
    "    for item in data[:4]:\n",
    "        f.write(json.dumps(item) + \"\\n\")\n",
    "with open(\"eval.jsonl\", \"w\") as f:\n",
    "    for item in data[5:9]:\n",
    "        f.write(json.dumps(item) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb19601e3b554374a75c14ed96f0b97d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdff5579c5624ae68789b34263de1490",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/5.70k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4e6e7cff1614016a393082d41fdb089",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afd1ae320ab844d6a4c2340e6a0e1ff7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ad1b3b465344e59bed2a13fa9a9d0f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/7.03M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79e32708616342c09ef83577c5dd1603",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "chat_template.json:   0%|          | 0.00/1.05k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]qwen-vl-utils using torchvision to read video.\n",
      "100%|| 4/4 [00:06<00:00,  1.72s/it]\n",
      "100%|| 4/4 [00:06<00:00,  1.58s/it]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from transformers import AutoProcessor\n",
    "from datasets import load_dataset, load_from_disk, Dataset, DatasetDict\n",
    "def load_json_dataset(train_data_path, eval_data_path, preprocessed_data_path= \"./dataset\"): # Modified to accept preprocessed_data_path\n",
    "    max_pixels = 3584 * 28 * 28\n",
    "    min_pixels = 16 * 28 * 28\n",
    "    processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2.5-VL-3B-Instruct\")\n",
    "    def create_dataset_from_json(file_path, split_name):\n",
    "        with open(file_path, 'r') as f:\n",
    "            data = [json.loads(line) for line in f if line.strip()]\n",
    "        examples = []\n",
    "        for video in tqdm(data):\n",
    "            timestamps = video[\"timestamp\"]\n",
    "            sentence = video[\"caption\"].strip().lower()\n",
    "            if sentence.endswith(\".\"):\n",
    "                sentence = sentence[:-1]\n",
    "    \n",
    "            video_path = video[\"video\"]\n",
    "            video_id = video_path.split(\"/\")[-1].split(\".\")[0]\n",
    "            \n",
    "            example_output_dir = video_path.split(\"/\")[-1].split(\".\")[0]\n",
    "            example_output_dir = f\"./dataset/{split_name}/{example_output_dir}\"\n",
    "            os.makedirs(example_output_dir, exist_ok=True)\n",
    "\n",
    "            _, video_inputs, video_kwargs, fps_inputs = preprocess_video_inner(video_path, processor, max_pixels, min_pixels)\n",
    "            torch.save(video_inputs, os.path.join(example_output_dir, \"video_inputs.pt\"))\n",
    "            with open(os.path.join(example_output_dir, \"video_kwargs.json\"), 'w') as f:\n",
    "                json.dump(video_kwargs, f)\n",
    "            \n",
    "            example_output_dir = os.path.join(preprocessed_data_path, split_name, f\"{video_id}\")\n",
    "            duration = get_duration(video[\"video\"])\n",
    "            solution = (float(timestamps[0]) / duration, float(timestamps[1]) / duration)\n",
    "            duration = get_duration(video[\"video\"])\n",
    "            example = {\n",
    "                \"problem\": sentence,\n",
    "                \"solution\": (timestamps[0], timestamps[1]),\n",
    "                \"video_path\": video_path,\n",
    "                \"durations\": duration,\n",
    "                \"preprocessed_path\": example_output_dir # Initialize preprocessed_path as None\n",
    "            }\n",
    "            if preprocessed_data_path != \"\": # If preprocessed data path is provided, construct the path\n",
    "                example[\"preprocessed_path\"] = os.path.join(preprocessed_data_path, split_name, f\"{video_id}\")\n",
    "            examples.append(example)\n",
    "        return examples\n",
    "        # random.shuffle(examples)\n",
    "        # print(len(examples))\n",
    "        # print(examples[:5])\n",
    "        # dataset = Dataset.from_list(examples)\n",
    "\n",
    "        # def __getitem__(self, idx): # Define getitem within the scope where dataset is available\n",
    "        #     example = dataset[idx]\n",
    "\n",
    "        #     # return example\n",
    "        #     data_to_return = {k: v for k, v in example.items()} # Create a copy to avoid modifying original dataset\n",
    "\n",
    "        #     # print(data_to_return)\n",
    "        #     # print(\"preprocessed_path:\", example[\"preprocessed_path\"])\n",
    "        #     if example[\"preprocessed_path\"] != \"\": # Check if preprocessed path exists\n",
    "        #         try:\n",
    "        #             # data_to_return[\"image_inputs\"] = [torch.load(os.path.join(example[\"preprocessed_path\"][0], \"image_inputs.pt\"))]\n",
    "        #             data_to_return[\"video_inputs\"] = [torch.load(os.path.join(example[\"preprocessed_path\"][0], \"video_inputs.pt\"))]\n",
    "        #             with open(os.path.join(example[\"preprocessed_path\"][0], \"video_kwargs.json\"), 'r') as f:\n",
    "        #                 data_to_return[\"video_kwargs\"] = [json.load(f)]\n",
    "        #             data_to_return[\"use_preprocessed\"] = [True] # Flag to indicate preprocessed data is used\n",
    "        #         except Exception as e:\n",
    "        #             print(f\"Warning: Error loading preprocessed data from {example['preprocessed_path'][0]}, falling back to video_path. Error: {e}\")\n",
    "        #             data_to_return[\"use_preprocessed\"] = [False] # Fallback to video_path if loading fails\n",
    "        #     else:\n",
    "        #         data_to_return[\"use_preprocessed\"] = [False] #  No preprocessed data to use or path invalid\n",
    "\n",
    "        #     return data_to_return\n",
    "\n",
    "        # dataset.__getitem__ = __getitem__.__get__(dataset, Dataset) # Bind getitem to the dataset\n",
    "\n",
    "        # return dataset\n",
    "\n",
    "    train_dataset = create_dataset_from_json(train_data_path, \"train\")\n",
    "    eval_dataset = create_dataset_from_json(eval_data_path, \"eval\")\n",
    "    return DatasetDict({\"train\": train_dataset, \"eval\": eval_dataset})\n",
    "dataset = load_json_dataset(\n",
    "    \"./train.jsonl\",\n",
    "    \"./eval.jsonl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting unsloth\n",
      "  Downloading unsloth-2025.5.6-py3-none-any.whl.metadata (46 kB)\n",
      "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m46.8/46.8 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: vllm in /opt/conda/lib/python3.10/site-packages (0.8.5.post1)\n",
      "Downloading unsloth-2025.5.6-py3-none-any.whl (265 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m265.6/265.6 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: unsloth\n",
      "Successfully installed unsloth-2025.5.6\n"
     ]
    }
   ],
   "source": [
    "!pip install --no-deps unsloth vllm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting unsloth_zoo\n",
      "  Downloading unsloth_zoo-2025.5.7-py3-none-any.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from unsloth_zoo) (2.6.0)\n",
      "Requirement already satisfied: triton>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from unsloth_zoo) (3.2.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from unsloth_zoo) (21.3)\n",
      "Collecting tyro (from unsloth_zoo)\n",
      "  Downloading tyro-0.9.20-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: transformers!=4.47.0,==4.51.3 in /opt/conda/lib/python3.10/site-packages (from unsloth_zoo) (4.51.3)\n",
      "Collecting datasets>=3.4.1 (from unsloth_zoo)\n",
      "  Downloading datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: sentencepiece>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from unsloth_zoo) (0.2.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from unsloth_zoo) (4.66.4)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from unsloth_zoo) (5.9.3)\n",
      "Requirement already satisfied: wheel>=0.42.0 in /opt/conda/lib/python3.10/site-packages (from unsloth_zoo) (0.43.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from unsloth_zoo) (1.26.4)\n",
      "Requirement already satisfied: accelerate>=0.34.1 in /opt/conda/lib/python3.10/site-packages (from unsloth_zoo) (0.34.2)\n",
      "Collecting trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9 (from unsloth_zoo)\n",
      "  Downloading trl-0.15.2-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: peft!=0.11.0,>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from unsloth_zoo) (0.15.2)\n",
      "Requirement already satisfied: protobuf<4.0.0 in /opt/conda/lib/python3.10/site-packages (from unsloth_zoo) (3.20.3)\n",
      "Requirement already satisfied: huggingface_hub>=0.30.0 in /opt/conda/lib/python3.10/site-packages (from unsloth_zoo) (0.31.4)\n",
      "Collecting hf_transfer (from unsloth_zoo)\n",
      "  Downloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting cut_cross_entropy (from unsloth_zoo)\n",
      "  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (from unsloth_zoo) (10.3.0)\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.10/site-packages (from unsloth_zoo) (2024.5.15)\n",
      "Requirement already satisfied: msgspec in /opt/conda/lib/python3.10/site-packages (from unsloth_zoo) (0.19.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers!=4.47.0,==4.51.3->unsloth_zoo) (3.18.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers!=4.47.0,==4.51.3->unsloth_zoo) (6.0.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers!=4.47.0,==4.51.3->unsloth_zoo) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.10/site-packages (from transformers!=4.47.0,==4.51.3->unsloth_zoo) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.10/site-packages (from transformers!=4.47.0,==4.51.3->unsloth_zoo) (0.4.5)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=3.4.1->unsloth_zoo) (16.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=3.4.1->unsloth_zoo) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets>=3.4.1->unsloth_zoo) (2.2.2)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets>=3.4.1->unsloth_zoo) (3.4.1)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/conda/lib/python3.10/site-packages (from datasets>=3.4.1->unsloth_zoo) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth_zoo) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub>=0.30.0->unsloth_zoo) (4.12.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->unsloth_zoo) (3.1.2)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->unsloth_zoo) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->unsloth_zoo) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /opt/conda/lib/python3.10/site-packages (from torch->unsloth_zoo) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /opt/conda/lib/python3.10/site-packages (from torch->unsloth_zoo) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /opt/conda/lib/python3.10/site-packages (from torch->unsloth_zoo) (12.4.127)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.10/site-packages (from torch->unsloth_zoo) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /opt/conda/lib/python3.10/site-packages (from torch->unsloth_zoo) (12.4.5.8)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /opt/conda/lib/python3.10/site-packages (from torch->unsloth_zoo) (11.2.1.3)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /opt/conda/lib/python3.10/site-packages (from torch->unsloth_zoo) (10.3.5.147)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /opt/conda/lib/python3.10/site-packages (from torch->unsloth_zoo) (11.6.1.9)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /opt/conda/lib/python3.10/site-packages (from torch->unsloth_zoo) (12.3.1.170)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /opt/conda/lib/python3.10/site-packages (from torch->unsloth_zoo) (0.6.2)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /opt/conda/lib/python3.10/site-packages (from torch->unsloth_zoo) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /opt/conda/lib/python3.10/site-packages (from torch->unsloth_zoo) (12.4.127)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /opt/conda/lib/python3.10/site-packages (from torch->unsloth_zoo) (12.4.127)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/conda/lib/python3.10/site-packages (from torch->unsloth_zoo) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy==1.13.1->torch->unsloth_zoo) (1.3.0)\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth_zoo) (13.7.1)\n",
      "Requirement already satisfied: docstring-parser>=0.15 in /opt/conda/lib/python3.10/site-packages (from tyro->unsloth_zoo) (0.16)\n",
      "Collecting shtab>=1.5.6 (from tyro->unsloth_zoo)\n",
      "  Downloading shtab-1.7.2-py3-none-any.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: typeguard>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from tyro->unsloth_zoo) (4.3.0)\n",
      "Collecting typing-extensions>=3.7.4.3 (from huggingface_hub>=0.30.0->unsloth_zoo)\n",
      "  Downloading typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth_zoo) (3.9.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers!=4.47.0,==4.51.3->unsloth_zoo) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers!=4.47.0,==4.51.3->unsloth_zoo) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers!=4.47.0,==4.51.3->unsloth_zoo) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers!=4.47.0,==4.51.3->unsloth_zoo) (2024.8.30)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth_zoo) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth_zoo) (2.18.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->unsloth_zoo) (2.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets>=3.4.1->unsloth_zoo) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets>=3.4.1->unsloth_zoo) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets>=3.4.1->unsloth_zoo) (2024.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth_zoo) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth_zoo) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth_zoo) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth_zoo) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth_zoo) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.4.1->unsloth_zoo) (4.0.3)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->trl!=0.15.0,!=0.9.0,!=0.9.1,!=0.9.2,!=0.9.3,<=0.15.2,>=0.7.9->unsloth_zoo) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.4.1->unsloth_zoo) (1.16.0)\n",
      "Downloading unsloth_zoo-2025.5.7-py3-none-any.whl (138 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m138.1/138.1 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading datasets-3.6.0-py3-none-any.whl (491 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m491.5/491.5 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading trl-0.15.2-py3-none-any.whl (318 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\n",
      "Downloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m66.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tyro-0.9.20-py3-none-any.whl (125 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m125.3/125.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading shtab-1.7.2-py3-none-any.whl (14 kB)\n",
      "Downloading typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
      "\u001b[2K   \u001b[90m\u001b[0m \u001b[32m45.8/45.8 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[33mWARNING: Error parsing requirements for numba: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/numba-0.60.0.dist-info/METADATA'\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: typing-extensions, shtab, hf_transfer, tyro, datasets, cut_cross_entropy, trl, unsloth_zoo\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.12.2\n",
      "    Uninstalling typing_extensions-4.12.2:\n",
      "      Successfully uninstalled typing_extensions-4.12.2\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 3.0.1\n",
      "    Uninstalling datasets-3.0.1:\n",
      "      Successfully uninstalled datasets-3.0.1\n",
      "  Attempting uninstall: trl\n",
      "    Found existing installation: trl 0.17.0\n",
      "    Uninstalling trl-0.17.0:\n",
      "      Successfully uninstalled trl-0.17.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "cudf 24.8.3 requires cubinlinker, which is not installed.\n",
      "cudf 24.8.3 requires cupy-cuda11x>=12.0.0, which is not installed.\n",
      "cudf 24.8.3 requires numba>=0.57, which is not installed.\n",
      "cudf 24.8.3 requires ptxcompiler, which is not installed.\n",
      "cuml 24.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\n",
      "cuml 24.8.0 requires numba>=0.57, which is not installed.\n",
      "dask-cudf 24.8.3 requires cupy-cuda11x>=12.0.0, which is not installed.\n",
      "librosa 0.10.2.post1 requires numba>=0.51.0, which is not installed.\n",
      "unsloth 2025.5.6 requires diffusers, which is not installed.\n",
      "vllm 0.8.5.post1 requires numba==0.61.2; python_version > \"3.9\", which is not installed.\n",
      "ydata-profiling 4.10.0 requires numba<1,>=0.56.0, which is not installed.\n",
      "apache-beam 2.46.0 requires cloudpickle~=2.2.1, but you have cloudpickle 3.0.0 which is incompatible.\n",
      "apache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\n",
      "apache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\n",
      "apache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 16.1.0 which is incompatible.\n",
      "bigframes 0.22.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.10.0, but you have google-cloud-bigquery 2.34.4 which is incompatible.\n",
      "bigframes 0.22.0 requires google-cloud-storage>=2.0.0, but you have google-cloud-storage 1.44.0 which is incompatible.\n",
      "bigframes 0.22.0 requires pandas<2.1.4,>=1.5.0, but you have pandas 2.2.2 which is incompatible.\n",
      "cudf 24.8.3 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.6.0 which is incompatible.\n",
      "dataproc-jupyter-plugin 0.1.79 requires pydantic~=1.10.0, but you have pydantic 2.9.2 which is incompatible.\n",
      "ibis-framework 7.1.0 requires pyarrow<15,>=2, but you have pyarrow 16.1.0 which is incompatible.\n",
      "jupyterlab 4.2.5 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\n",
      "jupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\n",
      "ydata-profiling 4.10.0 requires scipy<1.14,>=1.4.1, but you have scipy 1.14.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed cut_cross_entropy-25.1.1 datasets-3.6.0 hf_transfer-0.1.9 shtab-1.7.2 trl-0.15.2 typing-extensions-4.13.2 tyro-0.9.20 unsloth_zoo-2025.5.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install unsloth_zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.5.6: Fast Qwen2 patching. Transformers: 4.51.3. vLLM: 0.8.5.post1.\n",
      "   \\\\   /|    Tesla T4. Num GPUs = 2. Max memory: 14.741 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post2. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "source": [
    "import unsloth\n",
    "from unsloth import FastVisionModel \n",
    "import torch\n",
    "max_seq_length = 1024 # Can increase for longer reasoning traces\n",
    "lora_rank = 8 # Larger rank = smarter, but slower\n",
    "\n",
    "model, tokenizer = FastVisionModel.from_pretrained(\n",
    "    \"unsloth/Qwen2-VL-2B-Instruct-bnb-4bit\",\n",
    "    load_in_4bit = True, # Use 4bit to reduce memory use. False for 16bit LoRA.\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for long context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Making `model.base_model.model.model` require gradients\n"
     ]
    }
   ],
   "source": [
    "model = FastVisionModel.get_peft_model(\n",
    "    model,\n",
    "    finetune_vision_layers     = False, # False if not finetuning vision layers\n",
    "    finetune_language_layers   = True, # False if not finetuning language layers\n",
    "    finetune_attention_modules = True, # False if not finetuning attention layers\n",
    "    finetune_mlp_modules       = True, # False if not finetuning MLP layers\n",
    "\n",
    "    r = 4,           # The larger, the higher the accuracy, but might overfit\n",
    "    lora_alpha = 8,  # Recommended alpha == r at least\n",
    "    lora_dropout = 0,\n",
    "    bias = \"none\",\n",
    "    random_state = 3407,\n",
    "    use_rslora = False,  # We support rank stabilized LoRA\n",
    "    loftq_config = None, # And LoftQ\n",
    "    # target_modules = \"all-linear\", # Optional now! Can specify a list if needed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ffmpeg\n",
      "  Downloading ffmpeg-1.4.tar.gz (5.1 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hBuilding wheels for collected packages: ffmpeg\n",
      "  Building wheel for ffmpeg (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for ffmpeg: filename=ffmpeg-1.4-py3-none-any.whl size=6082 sha256=8b4c49db74c85afea1447c695e19b9e1e311c1f308b840423240323ac29ec182\n",
      "  Stored in directory: /root/.cache/pip/wheels/8e/7a/69/cd6aeb83b126a7f04cbe7c9d929028dc52a6e7d525ff56003a\n",
      "Successfully built ffmpeg\n",
      "\u001b[33mWARNING: Error parsing requirements for numba: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/numba-0.60.0.dist-info/METADATA'\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: ffmpeg\n",
      "Successfully installed ffmpeg-1.4\n"
     ]
    }
   ],
   "source": [
    "!pip install ffmpeg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### REWARD Functions\n",
    "import re\n",
    "from datetime import datetime\n",
    "def parse_timestamp_output(output_string):\n",
    "    \"\"\"Parses timestamp output, similar to the example code.\"\"\"\n",
    "    # 1. Find all <answer>...</answer> blocks.\n",
    "    answer_matches = re.findall(r\"<answer>(.*?)</answer>\", output_string, re.DOTALL)\n",
    "\n",
    "    if not answer_matches:\n",
    "        return None  # No <answer> tags found.\n",
    "\n",
    "    # 2. Use the content of the *last* <answer> block.\n",
    "    last_answer_content = answer_matches[-1]\n",
    "    print('last_answer_content:', last_answer_content)\n",
    "\n",
    "    matches = re.findall(r\"(\\d+\\.?\\d*) (to|and) (\\d+\\.?\\d*)\", last_answer_content, re.IGNORECASE)\n",
    "    if not matches:\n",
    "        return None\n",
    "    last_match = matches[-1]\n",
    "    start_time = float(last_match[0])\n",
    "    end_time = float(last_match[2])\n",
    "    return start_time, end_time\n",
    "\n",
    "def iou_timestamp_reward(completions, solution, durations, **kwargs): # Modified reward function name and arguments\n",
    "    \"\"\"Reward function that calculates IoU between predicted and ground truth timestamps.\"\"\"\n",
    "    # print(completions, solution, durations)\n",
    "    # contents = [completion[0][\"content\"] for completion in completions]\n",
    "    rewards = []\n",
    "    # print(completions, solution, durations, **kwargs)\n",
    "    current_time = datetime.now().strftime(\"%d-%H-%M-%S-%f\")\n",
    "    for content, sol, duration in zip(completions, solution, durations): # Added video_durations\n",
    "        reward = 0.0\n",
    "        parsed_times = parse_timestamp_output(content)\n",
    "        start_time, end_time = 0, 0\n",
    "        gt_start, gt_end = sol\n",
    "        # s, e = gt_start / duration, gt_end / duration\n",
    "        s, e = gt_start, gt_end\n",
    "        if parsed_times:\n",
    "            start_time, end_time = parsed_times\n",
    "            from_number = start_time\n",
    "            to_number = end_time\n",
    "\n",
    "            intersection = max(0, min(to_number, e) - max(from_number, s))\n",
    "            union = max(to_number, e) - min(from_number, s)\n",
    "            if union > 0:\n",
    "                iou = intersection / union   # 0.1 0.3\n",
    "\n",
    "            reward = iou\n",
    "\n",
    "        print('gt second:', gt_start, gt_end)\n",
    "        print('pred second:', start_time, end_time)\n",
    "        print(f\"------------- {current_time} IoU reward: {reward} -------------\\n\")\n",
    "\n",
    "        rewards.append(reward)\n",
    "\n",
    "        if os.getenv(\"DEBUG_MODE\") == \"true\":\n",
    "            log_path = os.getenv(\"LOG_PATH\")\n",
    "            with open(log_path, \"a\") as f:\n",
    "                f.write(f\"Content: {content}\\n\")\n",
    "                f.write(f\"pred second: {str(start_time)}, {str(end_time)}\\n\")\n",
    "                f.write(f\"gt second: {str(gt_start)}, {str(gt_end)}\\n\")\n",
    "                f.write(f\"------------- {current_time} IoU reward: {reward} -------------\\n\") # Modified log message\n",
    "\n",
    "    return rewards\n",
    "\n",
    "\n",
    "def format_reward(completions, **kwargs):\n",
    "    \"\"\"Reward function that checks if the completion has a specific format.\"\"\"\n",
    "    pattern = re.compile(r'<think>.*?</think>\\s*<answer>.*?</answer>', re.DOTALL)\n",
    "    matches = [re.fullmatch(pattern, content.strip()) for content in completions]\n",
    "    print('matches:', matches)\n",
    "    return [1.0 if match else 0.0 for match in matches]\n",
    "\n",
    "\n",
    "reward_funcs_registry = {\n",
    "    \"iou\": iou_timestamp_reward, # Modified registry to use iou_timestamp_reward\n",
    "    \"format\": format_reward,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'problem': \"[player] slaloms his way past challenges, but an opposing player does well to get the ball away. the ball goes behind for a corner. [team] will have an opportunity to threaten the opposition's goal\",\n",
       "  'solution': ('40.83', '57.67'),\n",
       "  'video_path': '/kaggle/input/grpo-dataset/data_grpo/2015-02-21 - 18-00 Chelsea 1 - 1 Burnley/MTBfMTVfMTFfMTVlOGYzND.mp4',\n",
       "  'durations': 60.0,\n",
       "  'preprocessed_path': './dataset/train/MTBfMTVfMTFfMTVlOGYzND'},\n",
       " {'problem': '[player] works the corner short',\n",
       "  'solution': ('17.99', '48.70'),\n",
       "  'video_path': '/kaggle/input/grpo-dataset/data_grpo/2015-02-21 - 18-00 Chelsea 1 - 1 Burnley/MTBfNDVfMTFfNDU2YTMzNT.mp4',\n",
       "  'durations': 60.0,\n",
       "  'preprocessed_path': './dataset/train/MTBfNDVfMTFfNDU2YTMzNT'},\n",
       " {'problem': \"[player] whips a promising cross into the box, but the opposition's defence intercepts the ball\",\n",
       "  'solution': ('40.34', '57.00'),\n",
       "  'video_path': '/kaggle/input/grpo-dataset/data_grpo/2015-02-21 - 18-00 Chelsea 1 - 1 Burnley/MTBfNDNfMTFfNDM0NzVkMm.mp4',\n",
       "  'durations': 60.0,\n",
       "  'preprocessed_path': './dataset/train/MTBfNDNfMTFfNDM0NzVkMm'},\n",
       " {'problem': 'goal! [player] provides [player] with a nice pass inside the box. it allows him to finish with a precise effort into the bottom right corner. 1:0',\n",
       "  'solution': ('52.88', '55.52'),\n",
       "  'video_path': '/kaggle/input/grpo-dataset/data_grpo/2015-02-21 - 18-00 Chelsea 1 - 1 Burnley/MTJfMTNfMTNfMTNjODg2ZD.mp4',\n",
       "  'durations': 60.0,\n",
       "  'preprocessed_path': './dataset/train/MTJfMTNfMTNfMTNjODg2ZD'}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-ffmpeg\n",
      "  Downloading python_ffmpeg-2.0.12-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting pyee (from python-ffmpeg)\n",
      "  Downloading pyee-13.0.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from python-ffmpeg) (4.13.2)\n",
      "Downloading python_ffmpeg-2.0.12-py3-none-any.whl (14 kB)\n",
      "Downloading pyee-13.0.0-py3-none-any.whl (15 kB)\n",
      "\u001b[33mWARNING: Error parsing requirements for numba: [Errno 2] No such file or directory: '/opt/conda/lib/python3.10/site-packages/numba-0.60.0.dist-info/METADATA'\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: pyee, python-ffmpeg\n",
      "Successfully installed pyee-13.0.0 python-ffmpeg-2.0.12\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade python-ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 4/4 [00:00<00:00, 46091.25it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from qwen_vl_utils import process_vision_info\n",
    "from transformers import AutoProcessor\n",
    "import ffmpeg\n",
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "from PIL import Image\n",
    "QUESTION_TEMPLATE = \"\"\"To accurately pinpoint soccer event \"[EVENT]\" in the video, determine the precise time period of the event.\n",
    "\n",
    "Output your thought process within the <think> </think> tags, including analysis with either specific timestamps (xx.xx) or time ranges (xx.xx to xx.xx) in <timestep> </timestep> tags.\n",
    "\n",
    "Then, provide the start and end times (in seconds, precise to two decimal places) in the format \"start time to end time\" within the <answer> </answer> tags. For example: \"12.54 to 17.83\".\"\"\"\n",
    "processor = AutoProcessor.from_pretrained(\"Qwen/Qwen2.5-VL-3B-Instruct\")\n",
    "\n",
    "def extract_frames(video_path, interval_sec=5):\n",
    "    \"\"\"\n",
    "    Extract frames from video every interval_sec seconds using OpenCV.\n",
    "    \n",
    "    Args:\n",
    "        video_path (str): Path to the video file\n",
    "        interval_sec (int): Time interval between frames (default 5 seconds)\n",
    "    \n",
    "    Returns:\n",
    "        list: List of paths to extracted frames\n",
    "    \"\"\"\n",
    "    # Create output directory from video filename (without extension)\n",
    "    output_dir = os.path.join('/kaggle/working', os.path.splitext(os.path.basename(video_path))[0])\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    \n",
    "    # Initialize video capture\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error opening video file: {video_path}\")\n",
    "        return []\n",
    "    \n",
    "    # Get video properties\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    duration = frame_count / fps\n",
    "    \n",
    "    # Calculate frame indices to extract\n",
    "    frames_to_extract = []\n",
    "    current_time = 0\n",
    "    while current_time < duration:\n",
    "        frame_idx = int(current_time * fps)\n",
    "        frames_to_extract.append(frame_idx)\n",
    "        current_time += interval_sec\n",
    "    \n",
    "    extracted_paths = []\n",
    "    for i, frame_idx in enumerate(tqdm(frames_to_extract, desc=\"Extracting frames\")):\n",
    "        # Set frame position\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if ret:\n",
    "            # Save the frame\n",
    "            output_path = os.path.join(output_dir, f'frame_{i:04d}.jpg')\n",
    "            cv2.imwrite(output_path, frame)\n",
    "            extracted_paths.append(output_path)\n",
    "        else:\n",
    "            print(f\"Failed to extract frame at index {frame_idx}\")\n",
    "    \n",
    "    cap.release()\n",
    "    print(f\"Extracted {len(extracted_paths)} frames to directory: {output_dir}\")\n",
    "    return extracted_paths\n",
    "def get_soccer_questions():\n",
    "    data_tempt = dataset['train']\n",
    "    mod_data = []\n",
    "    def process_example(x):\n",
    "        # frame_paths = extract_frames(x['video_path'])\n",
    "    \n",
    "    # Load images using PIL instead of OpenCV\n",
    "        # pil_images = [Image.open(path).convert('RGB') for path in frame_paths]\n",
    "        prompt = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"video\",\n",
    "                        \"video\": x['video_path'],\n",
    "                        \"max_pixels\": 224 * 398,\n",
    "                        \"fps\": 5.0,\n",
    "                    },\n",
    "                    {\"type\": \"text\", \"text\": QUESTION_TEMPLATE.replace(\"[EVENT]\", x['problem'])},\n",
    "                ],\n",
    "            },\n",
    "            {   \"role\": \"assistant\",\n",
    "                \"content\": [\n",
    "                {\"type\": \"text\",  \"text\": x['solution']} ]\n",
    "      },\n",
    "        ]\n",
    "        # text = processor.apply_chat_template(\n",
    "        #     prompt, tokenize=False, add_generation_prompt=True\n",
    "        # )\n",
    "        # _, video_inputs = process_vision_info(prompt, return_video_kwargs= False)\n",
    "        # inputs = processor(\n",
    "        #     text=[text],\n",
    "        #     images= None,\n",
    "        #     videos=video_inputs,\n",
    "        #     fps= 5.0,\n",
    "        #     padding=True,\n",
    "        #     return_tensors=\"pt\",\n",
    "        # )\n",
    "        # return inputs\n",
    "        return {\"prompt\": prompt}\n",
    "    for i in tqdm(range(len(data_tempt))):\n",
    "        example = process_example(data_tempt[i])\n",
    "        mod_data.append(example)\n",
    "    return mod_data\n",
    "\n",
    "train_data = get_soccer_questions()\n",
    "\n",
    "class SimpleDataCollator:\n",
    "    def __init__(self, tokenizer):\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __call__(self, features):\n",
    "        return self.tokenizer.pad(\n",
    "            features,\n",
    "            padding=True,\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "\n",
    "def format_and_tokenize(example):\n",
    "    messages = example[\"prompt\"]\n",
    "    input_text = processor.apply_chat_template(messages, add_generation_prompt=True)\n",
    "\n",
    "    # Process vision data (images and videos)\n",
    "    image_inputs, video_inputs = process_vision_info(messages)\n",
    "\n",
    "    # Tokenize text and add vision inputs\n",
    "    tokenized = processor(\n",
    "        text=input_text,\n",
    "        images=None,\n",
    "        videos=video_inputs,\n",
    "        add_special_tokens=False,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "\n",
    "    # Clone the tokenized input ids to create labels\n",
    "    tokenized[\"labels\"] = tokenized[\"input_ids\"].clone()\n",
    "    for k, v in tokenized.items():\n",
    "        # print(tokenized[\"answer\"])\n",
    "        \n",
    "        try:\n",
    "            tokenized[k] = v.squeeze(0)\n",
    "        except:\n",
    "            tokenized[k] = torch.tensor(v)\n",
    "\n",
    "    return tokenized\n",
    "\n",
    "tokenized_dataset = Dataset.from_list([format_and_tokenize(x) for x in train_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 4 | Num Epochs = 250 | Total steps = 250\n",
      "O^O/ \\_/ \\    Batch size per device = 4 | Gradient accumulation steps = 4\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (4 x 4 x 1) = 16\n",
      " \"-____-\"     Trainable parameters = 4,616,192/2,000,000,000 (0.23% trained)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to connect to the remote Jupyter Server 'https://kkb-production.jupyter-proxy.kaggle.net/k/240764989/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2IiwidHlwIjoiSldUIn0..QmlOX-mo_Q1P7HvMa_1ZdA.E3NGxeU_73fERfgKlNPmUxPpDrOAaGGb-T97K44FPi11ngs1Y-slE4DythkrqJefno3zQjZgZbpS2h0TQS4CvEMPp8t5_K8pYPLQ97WGy95V58FE88JCaLYatSa_Dg_BQ3TAkpbW2UO5RDWQgKxGis7H5k24k9wFw0UcgFdVTw71kCadvOvJCP-Zs7qO410N_nQ6ld3yJFxzoKCpCDXYlXQ1S7weSDy4Y3iVYAMEpD99A08LNFAeilZ_KYTX2uNI.2gM6mZR2-AJU9LcdFshlKQ/proxy'. Verify the server is running and reachable."
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel, is_bfloat16_supported\n",
    "from trl import GRPOConfig, GRPOTrainer\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "FastVisionModel.for_training(model) # Enable for training!\n",
    "\n",
    "training_args = GRPOConfig(\n",
    "    # use_vllm = True, # use vLLM for fast inference!\n",
    "    learning_rate = 5e-6,\n",
    "    adam_beta1 = 0.9,\n",
    "    adam_beta2 = 0.99,\n",
    "    weight_decay = 0.1,\n",
    "    warmup_ratio = 0.1,\n",
    "    lr_scheduler_type = \"cosine\",\n",
    "    optim = \"adamw_8bit\",\n",
    "    logging_steps = 1,\n",
    "    bf16 = is_bfloat16_supported(),\n",
    "    fp16 = not is_bfloat16_supported(),\n",
    "    per_device_train_batch_size = 1,\n",
    "    gradient_accumulation_steps = 4, # Increase to 4 for smoother training\n",
    "    num_generations = 8, # Decrease if out of memory\n",
    "    max_prompt_length = 256,\n",
    "    max_completion_length = 200,\n",
    "    # num_train_epochs = 1, # Set to 1 for a full training run\n",
    "    max_steps = 250,\n",
    "    save_steps = 250,\n",
    "    max_grad_norm = 0.1,\n",
    "    report_to = \"none\", # Can use Weights & Biases\n",
    "    output_dir = \"outputs\"\n",
    ")\n",
    "\n",
    "trainer = GRPOTrainer(\n",
    "    model = model,\n",
    "    processing_class = tokenizer,\n",
    "    reward_funcs = [\n",
    "        format_reward, \n",
    "        parse_timestamp_output, \n",
    "        iou_timestamp_reward\n",
    "    ],\n",
    "    args = training_args,\n",
    "    train_dataset = tokenized_dataset,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = GRPOTrainer(\n",
    "    model = model,\n",
    "    processing_class = tokenizer,\n",
    "    reward_funcs = [\n",
    "        format_reward, \n",
    "        parse_timestamp_output, \n",
    "        iou_timestamp_reward\n",
    "    ],\n",
    "    args = training_args,\n",
    "    train_dataset = train_dataset,\n",
    ")\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 4 | Num Epochs = 250 | Total steps = 250\n",
      "O^O/ \\_/ \\    Batch size per device = 4 | Gradient accumulation steps = 4\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (4 x 4 x 1) = 16\n",
      " \"-____-\"     Trainable parameters = 4,616,192/2,000,000,000 (0.23% trained)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Could not make a flat list of images from [{'input_ids': tensor([[151644,   8948,    198,   2610,    525,    264,  10950,  17847,     13,\n         151645,    198, 151644,    872,    198, 151652, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151653,   1249,  29257,  66538,  22174,   1538,\n            330,  33939,      0,    508,   3434,     60,   5707,    508,   3434,\n             60,    448,    264,   6419,   1494,   4766,    279,   3745,     13,\n            432,   6147,   1435,    311,   6248,    448,    264,  23560,   5041,\n           1119,    279,   5622,   1290,   9131,     13,    220,     16,     25,\n             15,      1,    304,    279,   2766,     11,   8253,    279,  23560,\n            882,   4168,    315,    279,   1538,    382,   5097,    697,   3381,\n           1882,   2878,    279,    366,  26865,     29,    690,  26865,     29,\n           9492,     11,   2670,   6358,    448,   2987,   3151,  48781,    320,\n           4146,  94329,      8,    476,    882,  21283,    320,   4146,  94329,\n            311,  20908,  94329,      8,    304,    366,     83,  48747,     29,\n            690,     83,  48747,     29,   9492,    382,  12209,     11,   3410,\n            279,   1191,    323,    835,   3039,    320,    258,   6486,     11,\n          23560,    311,   1378,  12122,   7482,      8,    304,    279,   3561,\n            330,   2468,    882,    311,    835,    882,      1,   2878,    279,\n            366,   9217,     29,    690,   9217,     29,   9492,     13,   1752,\n           3110,     25,    330,     16,     17,     13,     20,     19,    311,\n            220,     16,     22,     13,     23,     18,   3263, 151645,    198,\n         151644,  77091,    198]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'pixel_values_videos': tensor([[-1.3543, -1.1937, -1.2083,  ...,  0.0555,  0.0982, -0.2004],\n        [-1.4857, -1.1353, -1.1207,  ...,  0.0982, -0.1151, -0.1862],\n        [-1.6463, -1.0623, -0.7996,  ..., -0.2573, -0.2715, -0.1862],\n        ...,\n        [-0.1864, -0.1718, -0.1718,  ..., -0.3000, -0.2857, -0.2857],\n        [-0.2010, -0.2010, -0.2010,  ..., -0.3711, -0.3853, -0.4279],\n        [-0.2448, -0.2302, -0.2302,  ..., -0.3711, -0.3711, -0.3711]],\n       device='cuda:0'), 'video_grid_thw': tensor([[ 6, 16, 28]], device='cuda:0'), 'second_per_grid_ts': [0.4]}, {'input_ids': tensor([[151644,   8948,    198,   2610,    525,    264,  10950,  17847,     13,\n         151645,    198, 151644,    872,    198, 151652, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151653,   1249,  29257,  66538,  22174,   1538,\n            330,  33939,      0,    508,   3434,     60,   5707,    508,   3434,\n             60,    448,    264,   6419,   1494,   4766,    279,   3745,     13,\n            432,   6147,   1435,    311,   6248,    448,    264,  23560,   5041,\n           1119,    279,   5622,   1290,   9131,     13,    220,     16,     25,\n             15,      1,    304,    279,   2766,     11,   8253,    279,  23560,\n            882,   4168,    315,    279,   1538,    382,   5097,    697,   3381,\n           1882,   2878,    279,    366,  26865,     29,    690,  26865,     29,\n           9492,     11,   2670,   6358,    448,   2987,   3151,  48781,    320,\n           4146,  94329,      8,    476,    882,  21283,    320,   4146,  94329,\n            311,  20908,  94329,      8,    304,    366,     83,  48747,     29,\n            690,     83,  48747,     29,   9492,    382,  12209,     11,   3410,\n            279,   1191,    323,    835,   3039,    320,    258,   6486,     11,\n          23560,    311,   1378,  12122,   7482,      8,    304,    279,   3561,\n            330,   2468,    882,    311,    835,    882,      1,   2878,    279,\n            366,   9217,     29,    690,   9217,     29,   9492,     13,   1752,\n           3110,     25,    330,     16,     17,     13,     20,     19,    311,\n            220,     16,     22,     13,     23,     18,   3263, 151645,    198,\n         151644,  77091,    198]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'pixel_values_videos': tensor([[-1.3543, -1.1937, -1.2083,  ...,  0.0555,  0.0982, -0.2004],\n        [-1.4857, -1.1353, -1.1207,  ...,  0.0982, -0.1151, -0.1862],\n        [-1.6463, -1.0623, -0.7996,  ..., -0.2573, -0.2715, -0.1862],\n        ...,\n        [-0.1864, -0.1718, -0.1718,  ..., -0.3000, -0.2857, -0.2857],\n        [-0.2010, -0.2010, -0.2010,  ..., -0.3711, -0.3853, -0.4279],\n        [-0.2448, -0.2302, -0.2302,  ..., -0.3711, -0.3711, -0.3711]],\n       device='cuda:0'), 'video_grid_thw': tensor([[ 6, 16, 28]], device='cuda:0'), 'second_per_grid_ts': [0.4]}, {'input_ids': tensor([[151644,   8948,    198,   2610,    525,    264,  10950,  17847,     13,\n         151645,    198, 151644,    872,    198, 151652, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151653,   1249,  29257,  66538,  22174,   1538,\n          10545,   3434,     60,   4278,    279,   9131,   2805,      1,    304,\n            279,   2766,     11,   8253,    279,  23560,    882,   4168,    315,\n            279,   1538,    382,   5097,    697,   3381,   1882,   2878,    279,\n            366,  26865,     29,    690,  26865,     29,   9492,     11,   2670,\n           6358,    448,   2987,   3151,  48781,    320,   4146,  94329,      8,\n            476,    882,  21283,    320,   4146,  94329,    311,  20908,  94329,\n              8,    304,    366,     83,  48747,     29,    690,     83,  48747,\n             29,   9492,    382,  12209,     11,   3410,    279,   1191,    323,\n            835,   3039,    320,    258,   6486,     11,  23560,    311,   1378,\n          12122,   7482,      8,    304,    279,   3561,    330,   2468,    882,\n            311,    835,    882,      1,   2878,    279,    366,   9217,     29,\n            690,   9217,     29,   9492,     13,   1752,   3110,     25,    330,\n             16,     17,     13,     20,     19,    311,    220,     16,     22,\n             13,     23,     18,   3263, 151645,    198, 151644,  77091,    198]],\n       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1]], device='cuda:0'), 'pixel_values_videos': tensor([[-1.4419e+00, -1.0623e+00, -9.6015e-01,  ..., -1.5775e-01,\n         -1.3329e-03,  4.1327e-02],\n        [-1.2375e+00, -1.1645e+00, -1.0915e+00,  ...,  6.9767e-02,\n          1.1243e-01,  1.2887e-02],\n        [-1.3689e+00, -5.2220e-01, -2.8862e-01,  ..., -1.3329e-03,\n         -1.3329e-03, -7.2433e-02],\n        ...,\n        [-2.3023e-01, -2.3023e-01, -2.3023e-01,  ..., -4.5637e-01,\n         -4.5637e-01, -4.5637e-01],\n        [-2.4483e-01, -2.4483e-01, -2.4483e-01,  ..., -2.7151e-01,\n         -2.7151e-01, -2.4307e-01],\n        [-2.3023e-01, -2.3023e-01, -2.3023e-01,  ..., -4.9904e-01,\n         -5.2748e-01, -5.5592e-01]], device='cuda:0'), 'video_grid_thw': tensor([[ 6, 16, 28]], device='cuda:0'), 'second_per_grid_ts': [0.4]}, {'input_ids': tensor([[151644,   8948,    198,   2610,    525,    264,  10950,  17847,     13,\n         151645,    198, 151644,    872,    198, 151652, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151653,   1249,  29257,  66538,  22174,   1538,\n          10545,   3434,     60,   4278,    279,   9131,   2805,      1,    304,\n            279,   2766,     11,   8253,    279,  23560,    882,   4168,    315,\n            279,   1538,    382,   5097,    697,   3381,   1882,   2878,    279,\n            366,  26865,     29,    690,  26865,     29,   9492,     11,   2670,\n           6358,    448,   2987,   3151,  48781,    320,   4146,  94329,      8,\n            476,    882,  21283,    320,   4146,  94329,    311,  20908,  94329,\n              8,    304,    366,     83,  48747,     29,    690,     83,  48747,\n             29,   9492,    382,  12209,     11,   3410,    279,   1191,    323,\n            835,   3039,    320,    258,   6486,     11,  23560,    311,   1378,\n          12122,   7482,      8,    304,    279,   3561,    330,   2468,    882,\n            311,    835,    882,      1,   2878,    279,    366,   9217,     29,\n            690,   9217,     29,   9492,     13,   1752,   3110,     25,    330,\n             16,     17,     13,     20,     19,    311,    220,     16,     22,\n             13,     23,     18,   3263, 151645,    198, 151644,  77091,    198]],\n       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1]], device='cuda:0'), 'pixel_values_videos': tensor([[-1.4419e+00, -1.0623e+00, -9.6015e-01,  ..., -1.5775e-01,\n         -1.3329e-03,  4.1327e-02],\n        [-1.2375e+00, -1.1645e+00, -1.0915e+00,  ...,  6.9767e-02,\n          1.1243e-01,  1.2887e-02],\n        [-1.3689e+00, -5.2220e-01, -2.8862e-01,  ..., -1.3329e-03,\n         -1.3329e-03, -7.2433e-02],\n        ...,\n        [-2.3023e-01, -2.3023e-01, -2.3023e-01,  ..., -4.5637e-01,\n         -4.5637e-01, -4.5637e-01],\n        [-2.4483e-01, -2.4483e-01, -2.4483e-01,  ..., -2.7151e-01,\n         -2.7151e-01, -2.4307e-01],\n        [-2.3023e-01, -2.3023e-01, -2.3023e-01,  ..., -4.9904e-01,\n         -5.2748e-01, -5.5592e-01]], device='cuda:0'), 'video_grid_thw': tensor([[ 6, 16, 28]], device='cuda:0'), 'second_per_grid_ts': [0.4]}]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[41], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2245\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   2243\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   2244\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2245\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2246\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2250\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<string>:315\u001b[0m, in \u001b[0;36m_fast_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n",
      "File \u001b[0;32m<string>:25\u001b[0m, in \u001b[0;36m_unsloth_training_step\u001b[0;34m(self, model, inputs, num_items_in_batch)\u001b[0m\n",
      "File \u001b[0;32m/kaggle/working/unsloth_compiled_cache/UnslothGRPOTrainer.py:932\u001b[0m, in \u001b[0;36m_UnslothGRPOTrainer._prepare_inputs\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    930\u001b[0m prompts \u001b[38;5;241m=\u001b[39m [x[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m inputs]\n\u001b[1;32m    931\u001b[0m prompts_text \u001b[38;5;241m=\u001b[39m [maybe_apply_chat_template(example, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessing_class)[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m example \u001b[38;5;129;01min\u001b[39;00m inputs]\n\u001b[0;32m--> 932\u001b[0m prompt_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocessing_class\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    933\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompts_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_side\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mleft\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m    934\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    935\u001b[0m prompt_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_prepare_inputs(prompt_inputs)\n\u001b[1;32m    936\u001b[0m prompt_ids, prompt_mask \u001b[38;5;241m=\u001b[39m prompt_inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m], prompt_inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/qwen2_vl/processing_qwen2_vl.py:126\u001b[0m, in \u001b[0;36mQwen2VLProcessor.__call__\u001b[0;34m(self, images, text, videos, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m output_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_kwargs(\n\u001b[1;32m    121\u001b[0m     Qwen2VLProcessorKwargs,\n\u001b[1;32m    122\u001b[0m     tokenizer_init_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenizer\u001b[38;5;241m.\u001b[39minit_kwargs,\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    124\u001b[0m )\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m images \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 126\u001b[0m     image_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_processor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvideos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moutput_kwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimages_kwargs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m     image_grid_thw \u001b[38;5;241m=\u001b[39m image_inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimage_grid_thw\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/image_processing_utils.py:42\u001b[0m, in \u001b[0;36mBaseImageProcessor.__call__\u001b[0;34m(self, images, **kwargs)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, images, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BatchFeature:\n\u001b[1;32m     41\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Preprocess an image or a batch of images.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/qwen2_vl/image_processing_qwen2_vl.py:409\u001b[0m, in \u001b[0;36mQwen2VLImageProcessor.preprocess\u001b[0;34m(self, images, videos, do_resize, size, min_pixels, max_pixels, resample, do_rescale, rescale_factor, do_normalize, image_mean, image_std, patch_size, temporal_patch_size, merge_size, do_convert_rgb, return_tensors, data_format, input_data_format)\u001b[0m\n\u001b[1;32m    406\u001b[0m do_convert_rgb \u001b[38;5;241m=\u001b[39m do_convert_rgb \u001b[38;5;28;01mif\u001b[39;00m do_convert_rgb \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_convert_rgb\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m images \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 409\u001b[0m     images \u001b[38;5;241m=\u001b[39m \u001b[43mmake_flat_list_of_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m videos \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    411\u001b[0m     videos \u001b[38;5;241m=\u001b[39m make_batched_videos(videos)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/image_utils.py:262\u001b[0m, in \u001b[0;36mmake_flat_list_of_images\u001b[0;34m(images)\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m images\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m4\u001b[39m:\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(images)\n\u001b[0;32m--> 262\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not make a flat list of images from \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimages\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Could not make a flat list of images from [{'input_ids': tensor([[151644,   8948,    198,   2610,    525,    264,  10950,  17847,     13,\n         151645,    198, 151644,    872,    198, 151652, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151653,   1249,  29257,  66538,  22174,   1538,\n            330,  33939,      0,    508,   3434,     60,   5707,    508,   3434,\n             60,    448,    264,   6419,   1494,   4766,    279,   3745,     13,\n            432,   6147,   1435,    311,   6248,    448,    264,  23560,   5041,\n           1119,    279,   5622,   1290,   9131,     13,    220,     16,     25,\n             15,      1,    304,    279,   2766,     11,   8253,    279,  23560,\n            882,   4168,    315,    279,   1538,    382,   5097,    697,   3381,\n           1882,   2878,    279,    366,  26865,     29,    690,  26865,     29,\n           9492,     11,   2670,   6358,    448,   2987,   3151,  48781,    320,\n           4146,  94329,      8,    476,    882,  21283,    320,   4146,  94329,\n            311,  20908,  94329,      8,    304,    366,     83,  48747,     29,\n            690,     83,  48747,     29,   9492,    382,  12209,     11,   3410,\n            279,   1191,    323,    835,   3039,    320,    258,   6486,     11,\n          23560,    311,   1378,  12122,   7482,      8,    304,    279,   3561,\n            330,   2468,    882,    311,    835,    882,      1,   2878,    279,\n            366,   9217,     29,    690,   9217,     29,   9492,     13,   1752,\n           3110,     25,    330,     16,     17,     13,     20,     19,    311,\n            220,     16,     22,     13,     23,     18,   3263, 151645,    198,\n         151644,  77091,    198]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'pixel_values_videos': tensor([[-1.3543, -1.1937, -1.2083,  ...,  0.0555,  0.0982, -0.2004],\n        [-1.4857, -1.1353, -1.1207,  ...,  0.0982, -0.1151, -0.1862],\n        [-1.6463, -1.0623, -0.7996,  ..., -0.2573, -0.2715, -0.1862],\n        ...,\n        [-0.1864, -0.1718, -0.1718,  ..., -0.3000, -0.2857, -0.2857],\n        [-0.2010, -0.2010, -0.2010,  ..., -0.3711, -0.3853, -0.4279],\n        [-0.2448, -0.2302, -0.2302,  ..., -0.3711, -0.3711, -0.3711]],\n       device='cuda:0'), 'video_grid_thw': tensor([[ 6, 16, 28]], device='cuda:0'), 'second_per_grid_ts': [0.4]}, {'input_ids': tensor([[151644,   8948,    198,   2610,    525,    264,  10950,  17847,     13,\n         151645,    198, 151644,    872,    198, 151652, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151653,   1249,  29257,  66538,  22174,   1538,\n            330,  33939,      0,    508,   3434,     60,   5707,    508,   3434,\n             60,    448,    264,   6419,   1494,   4766,    279,   3745,     13,\n            432,   6147,   1435,    311,   6248,    448,    264,  23560,   5041,\n           1119,    279,   5622,   1290,   9131,     13,    220,     16,     25,\n             15,      1,    304,    279,   2766,     11,   8253,    279,  23560,\n            882,   4168,    315,    279,   1538,    382,   5097,    697,   3381,\n           1882,   2878,    279,    366,  26865,     29,    690,  26865,     29,\n           9492,     11,   2670,   6358,    448,   2987,   3151,  48781,    320,\n           4146,  94329,      8,    476,    882,  21283,    320,   4146,  94329,\n            311,  20908,  94329,      8,    304,    366,     83,  48747,     29,\n            690,     83,  48747,     29,   9492,    382,  12209,     11,   3410,\n            279,   1191,    323,    835,   3039,    320,    258,   6486,     11,\n          23560,    311,   1378,  12122,   7482,      8,    304,    279,   3561,\n            330,   2468,    882,    311,    835,    882,      1,   2878,    279,\n            366,   9217,     29,    690,   9217,     29,   9492,     13,   1752,\n           3110,     25,    330,     16,     17,     13,     20,     19,    311,\n            220,     16,     22,     13,     23,     18,   3263, 151645,    198,\n         151644,  77091,    198]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0'), 'pixel_values_videos': tensor([[-1.3543, -1.1937, -1.2083,  ...,  0.0555,  0.0982, -0.2004],\n        [-1.4857, -1.1353, -1.1207,  ...,  0.0982, -0.1151, -0.1862],\n        [-1.6463, -1.0623, -0.7996,  ..., -0.2573, -0.2715, -0.1862],\n        ...,\n        [-0.1864, -0.1718, -0.1718,  ..., -0.3000, -0.2857, -0.2857],\n        [-0.2010, -0.2010, -0.2010,  ..., -0.3711, -0.3853, -0.4279],\n        [-0.2448, -0.2302, -0.2302,  ..., -0.3711, -0.3711, -0.3711]],\n       device='cuda:0'), 'video_grid_thw': tensor([[ 6, 16, 28]], device='cuda:0'), 'second_per_grid_ts': [0.4]}, {'input_ids': tensor([[151644,   8948,    198,   2610,    525,    264,  10950,  17847,     13,\n         151645,    198, 151644,    872,    198, 151652, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151653,   1249,  29257,  66538,  22174,   1538,\n          10545,   3434,     60,   4278,    279,   9131,   2805,      1,    304,\n            279,   2766,     11,   8253,    279,  23560,    882,   4168,    315,\n            279,   1538,    382,   5097,    697,   3381,   1882,   2878,    279,\n            366,  26865,     29,    690,  26865,     29,   9492,     11,   2670,\n           6358,    448,   2987,   3151,  48781,    320,   4146,  94329,      8,\n            476,    882,  21283,    320,   4146,  94329,    311,  20908,  94329,\n              8,    304,    366,     83,  48747,     29,    690,     83,  48747,\n             29,   9492,    382,  12209,     11,   3410,    279,   1191,    323,\n            835,   3039,    320,    258,   6486,     11,  23560,    311,   1378,\n          12122,   7482,      8,    304,    279,   3561,    330,   2468,    882,\n            311,    835,    882,      1,   2878,    279,    366,   9217,     29,\n            690,   9217,     29,   9492,     13,   1752,   3110,     25,    330,\n             16,     17,     13,     20,     19,    311,    220,     16,     22,\n             13,     23,     18,   3263, 151645,    198, 151644,  77091,    198]],\n       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1]], device='cuda:0'), 'pixel_values_videos': tensor([[-1.4419e+00, -1.0623e+00, -9.6015e-01,  ..., -1.5775e-01,\n         -1.3329e-03,  4.1327e-02],\n        [-1.2375e+00, -1.1645e+00, -1.0915e+00,  ...,  6.9767e-02,\n          1.1243e-01,  1.2887e-02],\n        [-1.3689e+00, -5.2220e-01, -2.8862e-01,  ..., -1.3329e-03,\n         -1.3329e-03, -7.2433e-02],\n        ...,\n        [-2.3023e-01, -2.3023e-01, -2.3023e-01,  ..., -4.5637e-01,\n         -4.5637e-01, -4.5637e-01],\n        [-2.4483e-01, -2.4483e-01, -2.4483e-01,  ..., -2.7151e-01,\n         -2.7151e-01, -2.4307e-01],\n        [-2.3023e-01, -2.3023e-01, -2.3023e-01,  ..., -4.9904e-01,\n         -5.2748e-01, -5.5592e-01]], device='cuda:0'), 'video_grid_thw': tensor([[ 6, 16, 28]], device='cuda:0'), 'second_per_grid_ts': [0.4]}, {'input_ids': tensor([[151644,   8948,    198,   2610,    525,    264,  10950,  17847,     13,\n         151645,    198, 151644,    872,    198, 151652, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656, 151656,\n         151656, 151656, 151656, 151653,   1249,  29257,  66538,  22174,   1538,\n          10545,   3434,     60,   4278,    279,   9131,   2805,      1,    304,\n            279,   2766,     11,   8253,    279,  23560,    882,   4168,    315,\n            279,   1538,    382,   5097,    697,   3381,   1882,   2878,    279,\n            366,  26865,     29,    690,  26865,     29,   9492,     11,   2670,\n           6358,    448,   2987,   3151,  48781,    320,   4146,  94329,      8,\n            476,    882,  21283,    320,   4146,  94329,    311,  20908,  94329,\n              8,    304,    366,     83,  48747,     29,    690,     83,  48747,\n             29,   9492,    382,  12209,     11,   3410,    279,   1191,    323,\n            835,   3039,    320,    258,   6486,     11,  23560,    311,   1378,\n          12122,   7482,      8,    304,    279,   3561,    330,   2468,    882,\n            311,    835,    882,      1,   2878,    279,    366,   9217,     29,\n            690,   9217,     29,   9492,     13,   1752,   3110,     25,    330,\n             16,     17,     13,     20,     19,    311,    220,     16,     22,\n             13,     23,     18,   3263, 151645,    198, 151644,  77091,    198]],\n       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n         1, 1, 1]], device='cuda:0'), 'pixel_values_videos': tensor([[-1.4419e+00, -1.0623e+00, -9.6015e-01,  ..., -1.5775e-01,\n         -1.3329e-03,  4.1327e-02],\n        [-1.2375e+00, -1.1645e+00, -1.0915e+00,  ...,  6.9767e-02,\n          1.1243e-01,  1.2887e-02],\n        [-1.3689e+00, -5.2220e-01, -2.8862e-01,  ..., -1.3329e-03,\n         -1.3329e-03, -7.2433e-02],\n        ...,\n        [-2.3023e-01, -2.3023e-01, -2.3023e-01,  ..., -4.5637e-01,\n         -4.5637e-01, -4.5637e-01],\n        [-2.4483e-01, -2.4483e-01, -2.4483e-01,  ..., -2.7151e-01,\n         -2.7151e-01, -2.4307e-01],\n        [-2.3023e-01, -2.3023e-01, -2.3023e-01,  ..., -4.9904e-01,\n         -5.2748e-01, -5.5592e-01]], device='cuda:0'), 'video_grid_thw': tensor([[ 6, 16, 28]], device='cuda:0'), 'second_per_grid_ts': [0.4]}]"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
