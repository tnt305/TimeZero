{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/grpo-dataset-v1/antlr4_python3_runtime-4.13.2-py3-none-any.whl\n",
      "Installing collected packages: antlr4-python3-runtime\n",
      "Successfully installed antlr4-python3-runtime-4.13.2\n",
      "Processing /kaggle/input/grpo-dataset-v1/av-14.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Installing collected packages: av\n",
      "Successfully installed av-14.4.0\n",
      "Processing /kaggle/input/grpo-dataset-v1/bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl\n",
      "Requirement already satisfied: torch<3,>=2.0 in /opt/conda/lib/python3.10/site-packages (from bitsandbytes==0.45.5) (2.4.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from bitsandbytes==0.45.5) (1.26.4)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes==0.45.5) (3.15.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes==0.45.5) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes==0.45.5) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes==0.45.5) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes==0.45.5) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch<3,>=2.0->bitsandbytes==0.45.5) (2024.6.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch<3,>=2.0->bitsandbytes==0.45.5) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch<3,>=2.0->bitsandbytes==0.45.5) (1.3.0)\n",
      "Installing collected packages: bitsandbytes\n",
      "Successfully installed bitsandbytes-0.45.5\n",
      "Processing /kaggle/input/grpo-dataset-v1/blake3-1.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Installing collected packages: blake3\n",
      "Successfully installed blake3-1.0.4\n",
      "Processing /kaggle/input/grpo-dataset-v1/hjson-3.1.0-py3-none-any.whl\n",
      "Installing collected packages: hjson\n",
      "Successfully installed hjson-3.1.0\n",
      "Processing /kaggle/input/grpo-dataset-v1/einops-0.8.1-py3-none-any.whl\n",
      "Installing collected packages: einops\n",
      "Successfully installed einops-0.8.1\n",
      "Processing /kaggle/input/grpo-dataset-v1/deepspeed-0.16.5-py3-none-any.whl\n",
      "Requirement already satisfied: einops in /opt/conda/lib/python3.10/site-packages (from deepspeed==0.16.5) (0.8.1)\n",
      "Requirement already satisfied: hjson in /opt/conda/lib/python3.10/site-packages (from deepspeed==0.16.5) (3.1.0)\n",
      "Requirement already satisfied: msgpack in /opt/conda/lib/python3.10/site-packages (from deepspeed==0.16.5) (1.0.8)\n",
      "Requirement already satisfied: ninja in /opt/conda/lib/python3.10/site-packages (from deepspeed==0.16.5) (1.11.1.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from deepspeed==0.16.5) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from deepspeed==0.16.5) (21.3)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from deepspeed==0.16.5) (5.9.3)\n",
      "Requirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.10/site-packages (from deepspeed==0.16.5) (9.0.0)\n",
      "Requirement already satisfied: pydantic>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from deepspeed==0.16.5) (2.9.2)\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from deepspeed==0.16.5) (2.4.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from deepspeed==0.16.5) (4.66.4)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->deepspeed==0.16.5) (3.1.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.0.0->deepspeed==0.16.5) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.0.0->deepspeed==0.16.5) (2.23.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.0.0->deepspeed==0.16.5) (4.12.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->deepspeed==0.16.5) (3.15.1)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->deepspeed==0.16.5) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->deepspeed==0.16.5) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->deepspeed==0.16.5) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->deepspeed==0.16.5) (2024.6.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->deepspeed==0.16.5) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->deepspeed==0.16.5) (1.3.0)\n",
      "Installing collected packages: deepspeed\n",
      "Successfully installed deepspeed-0.16.5\n",
      "Processing /kaggle/input/grpo-dataset-v1/starlette-0.37.2-py3-none-any.whl\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /opt/conda/lib/python3.10/site-packages (from starlette==0.37.2) (4.4.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette==0.37.2) (3.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette==0.37.2) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette==0.37.2) (1.2.0)\n",
      "Requirement already satisfied: typing-extensions>=4.1 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette==0.37.2) (4.12.2)\n",
      "starlette is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n",
      "Processing /kaggle/input/grpo-dataset-v1/huggingface_hub-0.31.2-py3-none-any.whl\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub==0.31.2) (3.15.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub==0.31.2) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub==0.31.2) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub==0.31.2) (6.0.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub==0.31.2) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub==0.31.2) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub==0.31.2) (4.12.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub==0.31.2) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub==0.31.2) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub==0.31.2) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub==0.31.2) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub==0.31.2) (2024.8.30)\n",
      "Installing collected packages: huggingface-hub\n",
      "  Attempting uninstall: huggingface-hub\n",
      "    Found existing installation: huggingface-hub 0.25.1\n",
      "    Uninstalling huggingface-hub-0.25.1:\n",
      "      Successfully uninstalled huggingface-hub-0.25.1\n",
      "Successfully installed huggingface-hub-0.31.2\n",
      "Processing /kaggle/input/grpo-dataset-v1/tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /opt/conda/lib/python3.10/site-packages (from tokenizers==0.21.1) (0.31.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.21.1) (3.15.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.21.1) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.21.1) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.21.1) (6.0.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.21.1) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.21.1) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers==0.21.1) (4.12.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub<1.0,>=0.16.4->tokenizers==0.21.1) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers==0.21.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers==0.21.1) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers==0.21.1) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface-hub<1.0,>=0.16.4->tokenizers==0.21.1) (2024.8.30)\n",
      "Installing collected packages: tokenizers\n",
      "  Attempting uninstall: tokenizers\n",
      "    Found existing installation: tokenizers 0.20.0\n",
      "    Uninstalling tokenizers-0.20.0:\n",
      "      Successfully uninstalled tokenizers-0.20.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "transformers 4.45.1 requires tokenizers<0.21,>=0.20, but you have tokenizers 0.21.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed tokenizers-0.21.1\n",
      "Processing /kaggle/input/grpo-dataset-v1/transformers-4.51.3-py3-none-any.whl\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.51.3) (3.15.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.51.3) (0.31.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.51.3) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers==4.51.3) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.51.3) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.51.3) (2024.5.15)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers==4.51.3) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.10/site-packages (from transformers==4.51.3) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.10/site-packages (from transformers==4.51.3) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers==4.51.3) (4.66.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.51.3) (2024.6.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers==4.51.3) (4.12.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers==4.51.3) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.51.3) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.51.3) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.51.3) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers==4.51.3) (2024.8.30)\n",
      "Installing collected packages: transformers\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.45.1\n",
      "    Uninstalling transformers-4.45.1:\n",
      "      Successfully uninstalled transformers-4.45.1\n",
      "Successfully installed transformers-4.51.3\n",
      "Processing /kaggle/input/grpo-dataset-v1/compressed_tensors-0.9.3-py3-none-any.whl\n",
      "Requirement already satisfied: torch>=1.7.0 in /opt/conda/lib/python3.10/site-packages (from compressed-tensors==0.9.3) (2.4.0)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from compressed-tensors==0.9.3) (4.51.3)\n",
      "Requirement already satisfied: pydantic>=2.0 in /opt/conda/lib/python3.10/site-packages (from compressed-tensors==0.9.3) (2.9.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.0->compressed-tensors==0.9.3) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.0->compressed-tensors==0.9.3) (2.23.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic>=2.0->compressed-tensors==0.9.3) (4.12.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.0->compressed-tensors==0.9.3) (3.15.1)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.0->compressed-tensors==0.9.3) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.0->compressed-tensors==0.9.3) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.0->compressed-tensors==0.9.3) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.7.0->compressed-tensors==0.9.3) (2024.6.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /opt/conda/lib/python3.10/site-packages (from transformers->compressed-tensors==0.9.3) (0.31.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers->compressed-tensors==0.9.3) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers->compressed-tensors==0.9.3) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers->compressed-tensors==0.9.3) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->compressed-tensors==0.9.3) (2024.5.15)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers->compressed-tensors==0.9.3) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.10/site-packages (from transformers->compressed-tensors==0.9.3) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.10/site-packages (from transformers->compressed-tensors==0.9.3) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers->compressed-tensors==0.9.3) (4.66.4)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers->compressed-tensors==0.9.3) (3.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.7.0->compressed-tensors==0.9.3) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->compressed-tensors==0.9.3) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->compressed-tensors==0.9.3) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->compressed-tensors==0.9.3) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->compressed-tensors==0.9.3) (2024.8.30)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.7.0->compressed-tensors==0.9.3) (1.3.0)\n",
      "Installing collected packages: compressed-tensors\n",
      "Successfully installed compressed-tensors-0.9.3\n",
      "Processing /kaggle/input/grpo-dataset-v1/filelock-3.18.0-py3-none-any.whl\n",
      "Installing collected packages: filelock\n",
      "  Attempting uninstall: filelock\n",
      "    Found existing installation: filelock 3.15.1\n",
      "    Uninstalling filelock-3.15.1:\n",
      "      Successfully uninstalled filelock-3.15.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "ibis-framework 7.1.0 requires pyarrow<15,>=2, but you have pyarrow 16.1.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed filelock-3.18.0\n",
      "\u001b[31mERROR: flash_attn-2.7.42Bcu124torch2.6.0cxx11abiFALSE-cp312-cp312-win_amd64.whl is not a supported wheel on this platform.\u001b[0m\u001b[31m\n",
      "\u001b[0mProcessing /kaggle/input/grpo-dataset-v1/hf_xet-1.1.2-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Installing collected packages: hf-xet\n",
      "Successfully installed hf-xet-1.1.2\n",
      "Processing /kaggle/input/grpo-dataset-v1/jinja2-3.1.6-py3-none-any.whl\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2==3.1.6) (2.1.5)\n",
      "Installing collected packages: jinja2\n",
      "  Attempting uninstall: jinja2\n",
      "    Found existing installation: Jinja2 3.1.4\n",
      "    Uninstalling Jinja2-3.1.4:\n",
      "      Successfully uninstalled Jinja2-3.1.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "beatrix-jupyterlab 2024.66.154055 requires jupyterlab~=3.6.0, but you have jupyterlab 4.2.5 which is incompatible.\n",
      "distributed 2024.7.1 requires dask==2024.7.1, but you have dask 2024.9.1 which is incompatible.\n",
      "jupyterlab 4.2.5 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\n",
      "jupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\n",
      "rapids-dask-dependency 24.8.0a0 requires dask==2024.7.1, but you have dask 2024.9.1 which is incompatible.\n",
      "ydata-profiling 4.10.0 requires scipy<1.14,>=1.4.1, but you have scipy 1.14.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed jinja2-3.1.6\n",
      "Processing /kaggle/input/grpo-dataset-v1/latex2sympy2_extended-1.10.1-py3-none-any.whl\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from latex2sympy2-extended==1.10.1) (1.13.3)\n",
      "Requirement already satisfied: antlr4-python3-runtime<=4.13.2,>=4.9.3 in /opt/conda/lib/python3.10/site-packages (from latex2sympy2-extended==1.10.1) (4.13.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->latex2sympy2-extended==1.10.1) (1.3.0)\n",
      "Installing collected packages: latex2sympy2-extended\n",
      "Successfully installed latex2sympy2-extended-1.10.1\n",
      "Processing /kaggle/input/grpo-dataset-v1/math_verify-0.7.0-py3-none-any.whl\n",
      "Requirement already satisfied: latex2sympy2_extended==1.10.1 in /opt/conda/lib/python3.10/site-packages (from math-verify==0.7.0) (1.10.1)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from latex2sympy2_extended==1.10.1->math-verify==0.7.0) (1.13.3)\n",
      "Requirement already satisfied: antlr4-python3-runtime<=4.13.2,>=4.9.3 in /opt/conda/lib/python3.10/site-packages (from latex2sympy2_extended==1.10.1->math-verify==0.7.0) (4.13.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->latex2sympy2_extended==1.10.1->math-verify==0.7.0) (1.3.0)\n",
      "Installing collected packages: math-verify\n",
      "Successfully installed math-verify-0.7.0\n",
      "\u001b[31mERROR: opencv_python_headless-4.11.0.86-cp37-abi3-macosx_13_0_x86_64.whl is not a supported wheel on this platform.\u001b[0m\u001b[31m\n",
      "\u001b[0mProcessing /kaggle/input/grpo-dataset-v1/partial_json_parser-0.2.1.1.post5-py3-none-any.whl\n",
      "Installing collected packages: partial-json-parser\n",
      "Successfully installed partial-json-parser-0.2.1.1.post5\n",
      "Processing /kaggle/input/grpo-dataset-v1/fastapi-0.112.0-py3-none-any.whl\n",
      "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /opt/conda/lib/python3.10/site-packages (from fastapi==0.112.0) (0.37.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from fastapi==0.112.0) (2.9.2)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from fastapi==0.112.0) (4.12.2)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi==0.112.0) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi==0.112.0) (2.23.4)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /opt/conda/lib/python3.10/site-packages (from starlette<0.38.0,>=0.37.2->fastapi==0.112.0) (4.4.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette<0.38.0,>=0.37.2->fastapi==0.112.0) (3.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette<0.38.0,>=0.37.2->fastapi==0.112.0) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette<0.38.0,>=0.37.2->fastapi==0.112.0) (1.2.0)\n",
      "Installing collected packages: fastapi\n",
      "  Attempting uninstall: fastapi\n",
      "    Found existing installation: fastapi 0.111.0\n",
      "    Uninstalling fastapi-0.111.0:\n",
      "      Successfully uninstalled fastapi-0.111.0\n",
      "Successfully installed fastapi-0.112.0\n",
      "Processing /kaggle/input/grpo-dataset-v1/vllm-0.8.5.post1-cp38-abi3-manylinux1_x86_64.whl\n",
      "Requirement already satisfied: cachetools in /opt/conda/lib/python3.10/site-packages (from vllm==0.8.5.post1) (4.2.4)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from vllm==0.8.5.post1) (5.9.3)\n",
      "Requirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from vllm==0.8.5.post1) (0.2.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from vllm==0.8.5.post1) (1.26.4)\n",
      "Requirement already satisfied: requests>=2.26.0 in /opt/conda/lib/python3.10/site-packages (from vllm==0.8.5.post1) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from vllm==0.8.5.post1) (4.66.4)\n",
      "Requirement already satisfied: blake3 in /opt/conda/lib/python3.10/site-packages (from vllm==0.8.5.post1) (1.0.4)\n",
      "Requirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.10/site-packages (from vllm==0.8.5.post1) (9.0.0)\n",
      "Requirement already satisfied: transformers>=4.51.1 in /opt/conda/lib/python3.10/site-packages (from vllm==0.8.5.post1) (4.51.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.30.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub[hf_xet]>=0.30.0->vllm==0.8.5.post1) (0.31.2)\n",
      "Requirement already satisfied: tokenizers>=0.21.1 in /opt/conda/lib/python3.10/site-packages (from vllm==0.8.5.post1) (0.21.1)\n",
      "Requirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from vllm==0.8.5.post1) (3.20.3)\n",
      "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7d6fa9f370d0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/fastapi/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7d6fa9f360e0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/fastapi/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7d6fa9f36770>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/fastapi/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7d6fa9f50130>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/fastapi/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7d6fa9f50940>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/fastapi/\u001b[0m\u001b[33m\n",
      "\u001b[0mINFO: pip is looking at multiple versions of vllm to determine which version is compatible with other requirements. This could take a while.\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement fastapi>=0.115.0 (from vllm) (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for fastapi>=0.115.0\u001b[0m\u001b[31m\n",
      "\u001b[0mProcessing /kaggle/input/grpo-dataset-v1/peft-0.15.2-py3-none-any.whl\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft==0.15.2) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.15.2) (21.3)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft==0.15.2) (5.9.3)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft==0.15.2) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.15.2) (2.4.0)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft==0.15.2) (4.51.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from peft==0.15.2) (4.66.4)\n",
      "Requirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.15.2) (0.34.2)\n",
      "Requirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft==0.15.2) (0.4.5)\n",
      "Requirement already satisfied: huggingface_hub>=0.25.0 in /opt/conda/lib/python3.10/site-packages (from peft==0.15.2) (0.31.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface_hub>=0.25.0->peft==0.15.2) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub>=0.25.0->peft==0.15.2) (2024.6.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface_hub>=0.25.0->peft==0.15.2) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub>=0.25.0->peft==0.15.2) (4.12.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft==0.15.2) (3.1.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.15.2) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.15.2) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft==0.15.2) (3.1.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft==0.15.2) (2024.5.15)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.10/site-packages (from transformers->peft==0.15.2) (0.21.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft==0.15.2) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub>=0.25.0->peft==0.15.2) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub>=0.25.0->peft==0.15.2) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub>=0.25.0->peft==0.15.2) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub>=0.25.0->peft==0.15.2) (2024.8.30)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft==0.15.2) (1.3.0)\n",
      "Installing collected packages: peft\n",
      "Successfully installed peft-0.15.2\n",
      "Processing /kaggle/input/grpo-dataset-v1/python_multipart-0.0.20-py3-none-any.whl\n",
      "Installing collected packages: python-multipart\n",
      "  Attempting uninstall: python-multipart\n",
      "    Found existing installation: python-multipart 0.0.9\n",
      "    Uninstalling python-multipart-0.0.9:\n",
      "      Successfully uninstalled python-multipart-0.0.9\n",
      "Successfully installed python-multipart-0.0.20\n",
      "Processing /kaggle/input/grpo-dataset-v1/qwen_vl_utils-0.0.11-py3-none-any.whl\n",
      "Requirement already satisfied: av in /opt/conda/lib/python3.10/site-packages (from qwen-vl-utils==0.0.11) (14.4.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from qwen-vl-utils==0.0.11) (21.3)\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (from qwen-vl-utils==0.0.11) (10.3.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from qwen-vl-utils==0.0.11) (2.32.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->qwen-vl-utils==0.0.11) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->qwen-vl-utils==0.0.11) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->qwen-vl-utils==0.0.11) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->qwen-vl-utils==0.0.11) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->qwen-vl-utils==0.0.11) (2024.8.30)\n",
      "Installing collected packages: qwen-vl-utils\n",
      "Successfully installed qwen-vl-utils-0.0.11\n",
      "Processing /kaggle/input/grpo-dataset-v1/ray-2.46.0-cp310-cp310-manylinux2014_x86_64.whl\n",
      "Requirement already satisfied: click>=7.0 in /opt/conda/lib/python3.10/site-packages (from ray==2.46.0) (8.1.7)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from ray==2.46.0) (3.18.0)\n",
      "Requirement already satisfied: jsonschema in /opt/conda/lib/python3.10/site-packages (from ray==2.46.0) (4.22.0)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from ray==2.46.0) (1.0.8)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from ray==2.46.0) (21.3)\n",
      "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /opt/conda/lib/python3.10/site-packages (from ray==2.46.0) (3.20.3)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from ray==2.46.0) (6.0.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from ray==2.46.0) (2.32.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema->ray==2.46.0) (23.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema->ray==2.46.0) (2023.12.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema->ray==2.46.0) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema->ray==2.46.0) (0.18.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->ray==2.46.0) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->ray==2.46.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->ray==2.46.0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->ray==2.46.0) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->ray==2.46.0) (2024.8.30)\n",
      "Installing collected packages: ray\n",
      "  Attempting uninstall: ray\n",
      "    Found existing installation: ray 2.24.0\n",
      "    Uninstalling ray-2.24.0:\n",
      "      Successfully uninstalled ray-2.24.0\n",
      "Successfully installed ray-2.46.0\n",
      "Processing /kaggle/input/grpo-dataset-v1/rich_toolkit-0.14.6-py3-none-any.whl\n",
      "Requirement already satisfied: click>=8.1.7 in /opt/conda/lib/python3.10/site-packages (from rich-toolkit==0.14.6) (8.1.7)\n",
      "Requirement already satisfied: rich>=13.7.1 in /opt/conda/lib/python3.10/site-packages (from rich-toolkit==0.14.6) (13.7.1)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /opt/conda/lib/python3.10/site-packages (from rich-toolkit==0.14.6) (4.12.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=13.7.1->rich-toolkit==0.14.6) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich>=13.7.1->rich-toolkit==0.14.6) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=13.7.1->rich-toolkit==0.14.6) (0.1.2)\n",
      "Installing collected packages: rich-toolkit\n",
      "Successfully installed rich-toolkit-0.14.6\n",
      "Processing /kaggle/input/grpo-dataset-v1/sympy-1.13.1-py3-none-any.whl\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy==1.13.1) (1.3.0)\n",
      "Installing collected packages: sympy\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.13.3\n",
      "    Uninstalling sympy-1.13.3:\n",
      "      Successfully uninstalled sympy-1.13.3\n",
      "Successfully installed sympy-1.13.1\n",
      "Processing /kaggle/input/grpo-dataset-v1/torchao-0.11.0-cp39-abi3-manylinux_2_28_x86_64.manylinux_2_24_x86_64.whl\n",
      "Installing collected packages: torchao\n",
      "Successfully installed torchao-0.11.0\n",
      "Processing /kaggle/input/grpo-dataset-v1/triton-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Installing collected packages: triton\n",
      "Successfully installed triton-3.2.0\n",
      "Processing /kaggle/input/grpo-dataset-v1/trl-0.17.0-py3-none-any.whl\n",
      "Requirement already satisfied: accelerate>=0.34.0 in /opt/conda/lib/python3.10/site-packages (from trl==0.17.0) (0.34.2)\n",
      "Requirement already satisfied: datasets>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from trl==0.17.0) (3.0.1)\n",
      "Requirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from trl==0.17.0) (13.7.1)\n",
      "Requirement already satisfied: transformers>=4.46.0 in /opt/conda/lib/python3.10/site-packages (from trl==0.17.0) (4.51.3)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.34.0->trl==0.17.0) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.34.0->trl==0.17.0) (21.3)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.34.0->trl==0.17.0) (5.9.3)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.34.0->trl==0.17.0) (6.0.2)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.34.0->trl==0.17.0) (2.4.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.34.0->trl==0.17.0) (0.31.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.34.0->trl==0.17.0) (0.4.5)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=3.0.0->trl==0.17.0) (3.18.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=3.0.0->trl==0.17.0) (16.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=3.0.0->trl==0.17.0) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets>=3.0.0->trl==0.17.0) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets>=3.0.0->trl==0.17.0) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.10/site-packages (from datasets>=3.0.0->trl==0.17.0) (4.66.4)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets>=3.0.0->trl==0.17.0) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets>=3.0.0->trl==0.17.0) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets>=3.0.0->trl==0.17.0) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=3.0.0->trl==0.17.0) (3.9.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.46.0->trl==0.17.0) (2024.5.15)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.10/site-packages (from transformers>=4.46.0->trl==0.17.0) (0.21.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->trl==0.17.0) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->trl==0.17.0) (2.18.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=3.0.0->trl==0.17.0) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=3.0.0->trl==0.17.0) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=3.0.0->trl==0.17.0) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=3.0.0->trl==0.17.0) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=3.0.0->trl==0.17.0) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=3.0.0->trl==0.17.0) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.0->accelerate>=0.34.0->trl==0.17.0) (4.12.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->trl==0.17.0) (0.1.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate>=0.34.0->trl==0.17.0) (3.1.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=3.0.0->trl==0.17.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=3.0.0->trl==0.17.0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=3.0.0->trl==0.17.0) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=3.0.0->trl==0.17.0) (2024.8.30)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.34.0->trl==0.17.0) (1.13.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.34.0->trl==0.17.0) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate>=0.34.0->trl==0.17.0) (3.1.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets>=3.0.0->trl==0.17.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets>=3.0.0->trl==0.17.0) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets>=3.0.0->trl==0.17.0) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.0.0->trl==0.17.0) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate>=0.34.0->trl==0.17.0) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate>=0.34.0->trl==0.17.0) (1.3.0)\n",
      "Installing collected packages: trl\n",
      "Successfully installed trl-0.17.0\n",
      "Processing /kaggle/input/grpo-dataset-v1/numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Installing collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.4\n",
      "    Uninstalling numpy-1.26.4:\n",
      "      Successfully uninstalled numpy-1.26.4\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "cudf 24.8.3 requires cubinlinker, which is not installed.\n",
      "cudf 24.8.3 requires cupy-cuda11x>=12.0.0, which is not installed.\n",
      "cudf 24.8.3 requires ptxcompiler, which is not installed.\n",
      "cuml 24.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\n",
      "dask-cudf 24.8.3 requires cupy-cuda11x>=12.0.0, which is not installed.\n",
      "ucxx 0.39.1 requires libucx>=1.15.0, which is not installed.\n",
      "apache-beam 2.46.0 requires cloudpickle~=2.2.1, but you have cloudpickle 3.0.0 which is incompatible.\n",
      "apache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\n",
      "apache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\n",
      "apache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 16.1.0 which is incompatible.\n",
      "cesium 0.12.3 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
      "cudf 24.8.3 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.6.0 which is incompatible.\n",
      "gensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.14.1 which is incompatible.\n",
      "ibis-framework 7.1.0 requires pyarrow<15,>=2, but you have pyarrow 16.1.0 which is incompatible.\n",
      "libpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\n",
      "libpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\n",
      "rmm 24.8.2 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.6.0 which is incompatible.\n",
      "xarray 2024.9.0 requires packaging>=23.1, but you have packaging 21.3 which is incompatible.\n",
      "ydata-profiling 4.10.0 requires scipy<1.14,>=1.4.1, but you have scipy 1.14.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed numpy-1.26.4\n",
      "Processing /kaggle/input/grpo-dataset-v1/filelock-3.18.0-py3-none-any.whl\n",
      "filelock is already installed with the same version as the provided wheel. Use --force-reinstall to force an installation of the wheel.\n",
      "Processing /kaggle/input/grpo-dataset-v1/optree-0.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /opt/conda/lib/python3.10/site-packages (from optree==0.14.0) (4.12.2)\n",
      "Installing collected packages: optree\n",
      "  Attempting uninstall: optree\n",
      "    Found existing installation: optree 0.11.0\n",
      "    Uninstalling optree-0.11.0:\n",
      "      Successfully uninstalled optree-0.11.0\n",
      "Successfully installed optree-0.14.0\n"
     ]
    }
   ],
   "source": [
    "!pip install /kaggle/input/grpo-dataset-v1/antlr4_python3_runtime-4.13.2-py3-none-any.whl  \n",
    "!pip install /kaggle/input/grpo-dataset-v1/av-14.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl \n",
    "!pip install /kaggle/input/grpo-dataset-v1/bitsandbytes-0.45.5-py3-none-manylinux_2_24_x86_64.whl \n",
    "!pip install /kaggle/input/grpo-dataset-v1/blake3-1.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl \n",
    "!pip install /kaggle/input/grpo-dataset-v1/hjson-3.1.0-py3-none-any.whl \n",
    "!pip install /kaggle/input/grpo-dataset-v1/einops-0.8.1-py3-none-any.whl \n",
    "!pip install /kaggle/input/grpo-dataset-v1/deepspeed-0.16.5-py3-none-any.whl \n",
    "!pip install /kaggle/input/grpo-dataset-v1/starlette-0.37.2-py3-none-any.whl \n",
    "!pip install /kaggle/input/grpo-dataset-v1/huggingface_hub-0.31.2-py3-none-any.whl\n",
    "!pip install /kaggle/input/grpo-dataset-v1/tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl \n",
    "!pip install /kaggle/input/grpo-dataset-v1/transformers-4.51.3-py3-none-any.whl \n",
    "!pip install /kaggle/input/grpo-dataset-v1/compressed_tensors-0.9.3-py3-none-any.whl \n",
    "!pip install /kaggle/input/grpo-dataset-v1/filelock-3.18.0-py3-none-any.whl \n",
    "!pip install /kaggle/input/grpo-dataset-v1/flash_attn-2.7.42Bcu124torch2.6.0cxx11abiFALSE-cp312-cp312-win_amd64.whl \n",
    "!pip install /kaggle/input/grpo-dataset-v1/hf_xet-1.1.2-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl \n",
    "!pip install /kaggle/input/grpo-dataset-v1/jinja2-3.1.6-py3-none-any.whl \n",
    "!pip install /kaggle/input/grpo-dataset-v1/latex2sympy2_extended-1.10.1-py3-none-any.whl \n",
    "!pip install /kaggle/input/grpo-dataset-v1/math_verify-0.7.0-py3-none-any.whl \n",
    "!pip install /kaggle/input/grpo-dataset-v1/opencv_python_headless-4.11.0.86-cp37-abi3-macosx_13_0_x86_64.whl \n",
    "!pip install /kaggle/input/grpo-dataset-v1/partial_json_parser-0.2.1.1.post5-py3-none-any.whl\n",
    "!pip install /kaggle/input/grpo-dataset-v1/fastapi-0.112.0-py3-none-any.whl\n",
    "!pip install /kaggle/input/grpo-dataset-v1/vllm-0.8.5.post1-cp38-abi3-manylinux1_x86_64.whl \n",
    "!pip install /kaggle/input/grpo-dataset-v1/peft-0.15.2-py3-none-any.whl \n",
    "!pip install /kaggle/input/grpo-dataset-v1/python_multipart-0.0.20-py3-none-any.whl \n",
    "!pip install /kaggle/input/grpo-dataset-v1/qwen_vl_utils-0.0.11-py3-none-any.whl \n",
    "!pip install /kaggle/input/grpo-dataset-v1/ray-2.46.0-cp310-cp310-manylinux2014_x86_64.whl \n",
    "!pip install /kaggle/input/grpo-dataset-v1/rich_toolkit-0.14.6-py3-none-any.whl \n",
    "!pip install /kaggle/input/grpo-dataset-v1/sympy-1.13.1-py3-none-any.whl \n",
    "!pip install /kaggle/input/grpo-dataset-v1/torchao-0.11.0-cp39-abi3-manylinux_2_28_x86_64.manylinux_2_24_x86_64.whl \n",
    "!pip install /kaggle/input/grpo-dataset-v1/triton-3.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl \n",
    "!pip install /kaggle/input/grpo-dataset-v1/trl-0.17.0-py3-none-any.whl \n",
    "!pip install /kaggle/input/grpo-dataset-v1/numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl --force-reinstall\n",
    "!pip install /kaggle/input/grpo-dataset-v1/filelock-3.18.0-py3-none-any.whl\n",
    "!pip install /kaggle/input/grpo-dataset-v1/optree-0.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/grpo-dataset-v1/torch-2.6.0-cp310-cp310-manylinux1_x86_64.whl\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch==2.6.0) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/conda/lib/python3.10/site-packages (from torch==2.6.0) (4.12.2)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.6.0) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch==2.6.0) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch==2.6.0) (2024.6.1)\n",
      "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7e4a8654e710>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/nvidia-cuda-nvrtc-cu12/\u001b[0m\u001b[33m\n",
      "\u001b[0m^C\n"
     ]
    }
   ],
   "source": [
    "!pip install /kaggle/input/grpo-dataset-v1/torch-2.6.0-cp310-cp310-manylinux1_x86_64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/grpo-dataset-v1/nvidia_cuda_nvrtc_cu12-12.9.41-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl\n",
      "Installing collected packages: nvidia-cuda-nvrtc-cu12\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.9.41\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.9.41:\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.9.41\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torch 2.6.0 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
      "torch 2.6.0 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
      "torch 2.6.0 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
      "torch 2.6.0 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
      "torch 2.6.0 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
      "torch 2.6.0 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
      "torch 2.6.0 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
      "torch 2.6.0 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
      "torch 2.6.0 requires nvidia-cusparselt-cu12==0.6.2; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
      "torch 2.6.0 requires nvidia-nccl-cu12==2.21.5; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
      "torch 2.6.0 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
      "torch 2.6.0 requires nvidia-nvtx-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n",
      "torch 2.6.0 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.9.41 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed nvidia-cuda-nvrtc-cu12-12.9.41\n"
     ]
    }
   ],
   "source": [
    "!pip install /kaggle/input/grpo-dataset-v1/nvidia_cuda_nvrtc_cu12-12.9.41-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl --force-reinstall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /kaggle/input/grpo-dataset-v1/torchvision-0.21.0-cp310-cp310-manylinux1_x86_64.whl\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision==0.21.0) (1.26.4)\n",
      "Requirement already satisfied: torch==2.6.0 in /opt/conda/lib/python3.10/site-packages (from torchvision==0.21.0) (2.6.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision==0.21.0) (10.3.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch==2.6.0->torchvision==0.21.0) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/conda/lib/python3.10/site-packages (from torch==2.6.0->torchvision==0.21.0) (4.12.2)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch==2.6.0->torchvision==0.21.0) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch==2.6.0->torchvision==0.21.0) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch==2.6.0->torchvision==0.21.0) (2024.6.1)\n",
      "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7d7f507f5e40>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/nvidia-cuda-nvrtc-cu12/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7d7f507f4e80>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/nvidia-cuda-nvrtc-cu12/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7d7f507f4910>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/nvidia-cuda-nvrtc-cu12/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7d7f5092b940>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/nvidia-cuda-nvrtc-cu12/\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7d7f5092b8b0>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/nvidia-cuda-nvrtc-cu12/\u001b[0m\u001b[33m\n",
      "\u001b[0mINFO: pip is looking at multiple versions of torch to determine which version is compatible with other requirements. This could take a while.\n",
      "\u001b[33mWARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x7d7f507eb070>: Failed to establish a new connection: [Errno -3] Temporary failure in name resolution')': /simple/torch/\u001b[0m\u001b[33m\n",
      "\u001b[0m^C\n"
     ]
    }
   ],
   "source": [
    "!pip install /kaggle/input/grpo-dataset-v1/torchvision-0.21.0-cp310-cp310-manylinux1_x86_64.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import os\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoProcessor\n",
    "from qwen_vl_utils import process_vision_info\n",
    "input_file = \"/kaggle/input/grpo-dataset/unique_videos.jsonl\"\n",
    "MODEL_NAME = \"/kaggle/working/Qwen2.5-VL-3B-Instruct\"\n",
    "\n",
    "\n",
    "def get_duration(video_path):\n",
    "    if not os.path.exists(video_path):\n",
    "        # raise FileNotFoundError(f\"Video file not found: {video_path}\")\n",
    "        print(f\"Video file not found: {video_path}\")\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    if not cap.isOpened():\n",
    "        raise RuntimeError(f\"Failed to open video: {video_path}\")\n",
    "\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_count = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    cap.release()\n",
    "\n",
    "    if fps > 0:\n",
    "        duration = frame_count / fps\n",
    "    else:\n",
    "        duration = 0\n",
    "\n",
    "    return duration\n",
    "\n",
    "\n",
    "def preprocess_video_inner(video_path, processor, max_pixels, min_pixels):\n",
    "    messages = [\n",
    "        {\"role\": \"user\", \"content\": [\n",
    "                {\"type\": \"video\",\n",
    "                \"video\": video_path,\n",
    "                \"total_pixels\": max_pixels,\n",
    "                \"min_pixels\": min_pixels,\n",
    "                },\n",
    "            ]\n",
    "        },\n",
    "    ]\n",
    "    image_inputs, video_inputs, video_kwargs = process_vision_info([messages], return_video_kwargs=True)\n",
    "    fps_inputs = video_kwargs['fps']\n",
    "    return image_inputs, video_inputs, video_kwargs, fps_inputs\n",
    "\n",
    "def process_single_video(task_args):\n",
    "    video_path, processor, max_pixels, min_pixels, example_output_dir, sentence, solution, duration = task_args\n",
    "    image_inputs, video_inputs, video_kwargs, fps_inputs = preprocess_video_inner(video_path, processor, max_pixels, min_pixels)\n",
    "\n",
    "\n",
    "    example_output_dir = video_path.split(\"/\")[-1].split(\".\")[0]\n",
    "    example_output_dir = f\"./dataset/train/{example_output_dir}\"\n",
    "    os.makedirs(example_output_dir, exist_ok=True)\n",
    "    torch.save(video_inputs, os.path.join(example_output_dir, \"video_inputs.pt\"))\n",
    "    with open(os.path.join(example_output_dir, \"video_kwargs.json\"), 'w') as f:\n",
    "        json.dump(video_kwargs, f)\n",
    "\n",
    "    return {\n",
    "            \"problem\": sentence,\n",
    "            \"solution\": solution,\n",
    "            \"preprocessed_path\": example_output_dir,\n",
    "            \"duration\": duration,\n",
    "            \"status\": \"success\"\n",
    "        }\n",
    "\n",
    "\n",
    "with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = [json.loads(line) for line in f if line.strip()]\n",
    "\n",
    "def process_split(file_path, split_name, output_dir, max_pixels, min_pixels, processor):\n",
    "    processor = AutoProcessor.from_pretrained(MODEL_NAME)\n",
    "\n",
    "    output_split_dir = os.path.join(output_dir, split_name)\n",
    "    os.makedirs(output_split_dir, exist_ok=True)\n",
    "\n",
    "    with open(file_path, 'r') as f:\n",
    "        data = [json.loads(line.strip()) for line in f]\n",
    "    data = data[: 10]\n",
    "    examples = []\n",
    "    tasks = []\n",
    "\n",
    "    for video in tqdm(data):\n",
    "        timestamps = video[\"timestamp\"]\n",
    "        sentence = video[\"caption\"].strip().lower()\n",
    "        if sentence.endswith(\".\"):\n",
    "            sentence = sentence[:-1]\n",
    "\n",
    "        video_path = video[\"video\"]\n",
    "        video_id = video_path.split(\"/\")[-1].split(\".\")[0]\n",
    "\n",
    "        example_output_dir = os.path.join(output_split_dir, f\"{video_id}\")\n",
    "        duration = get_duration(video[\"video\"])\n",
    "        solution = (float(timestamps[0]) / duration, float(timestamps[1]) / duration)\n",
    "\n",
    "        tasks.append((video_path, processor, max_pixels, min_pixels, example_output_dir, sentence, solution, duration))\n",
    "    print(\"task has ended\")\n",
    "    return tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/TimeZero\n"
     ]
    }
   ],
   "source": [
    "%cd TimeZero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "wandb.login(key=\"02ba155e26496a78f062f683274330566fefe94c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-05-18 11:19:17,921] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2025-05-18 11:19:17,921] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2025-05-18 11:19:17,921] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2025-05-18 11:19:17,921] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "df: /root/.triton/autotune: No such file or directory\n",
      "df: df: /root/.triton/autotune/root/.triton/autotune: No such file or directory: No such file or directory\n",
      "\n",
      "df: /root/.triton/autotune: No such file or directory\n",
      "[2025-05-18 11:19:21,915] [INFO] [comm.py:658:init_distributed] cdb=None\n",
      "[2025-05-18 11:19:21,915] [INFO] [comm.py:658:init_distributed] cdb=None\n",
      "[2025-05-18 11:19:21,915] [INFO] [comm.py:689:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "[2025-05-18 11:19:21,916] [INFO] [comm.py:658:init_distributed] cdb=None\n",
      "[2025-05-18 11:19:21,918] [INFO] [comm.py:658:init_distributed] cdb=None\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]qwen-vl-utils using torchvision to read video.\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]qwen-vl-utils using torchvision to read video.\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]qwen-vl-utils using torchvision to read video.\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]qwen-vl-utils using torchvision to read video.\n",
      "100%|| 4/4 [00:07<00:00,  1.87s/it]\n",
      "100%|| 4/4 [00:07<00:00,  1.85s/it]\n",
      "100%|| 4/4 [00:07<00:00,  1.87s/it]\n",
      "100%|| 4/4 [00:07<00:00,  1.87s/it]\n",
      "100%|| 4/4 [00:07<00:00,  1.88s/it]\n",
      "100%|| 4/4 [00:07<00:00,  1.86s/it]\n",
      "100%|| 4/4 [00:07<00:00,  1.86s/it]\n",
      "Using trainer class: <class 'src.open_r1.trainer.grpo_trainer_video.Qwen2VLGRPOTrainer_Video'>\n",
      "Using trainer class: <class 'src.open_r1.trainer.grpo_trainer_video.Qwen2VLGRPOTrainer_Video'>\n",
      "Sliding Window Attention is enabled but not implemented for `eager`; unexpected results may be encountered.\n",
      "Sliding Window Attention is enabled but not implemented for `eager`; unexpected results may be encountered.\n",
      "Using trainer class: <class 'src.open_r1.trainer.grpo_trainer_video.Qwen2VLGRPOTrainer_Video'>\n",
      "100%|| 4/4 [00:07<00:00,  1.88s/it]\n",
      "Sliding Window Attention is enabled but not implemented for `eager`; unexpected results may be encountered.\n",
      "Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]Using trainer class: <class 'src.open_r1.trainer.grpo_trainer_video.Qwen2VLGRPOTrainer_Video'>\n",
      "Sliding Window Attention is enabled but not implemented for `eager`; unexpected results may be encountered.\n",
      "Loading checkpoint shards: 100%|| 2/2 [00:02<00:00,  1.06s/it]\n",
      "[2025-05-18 11:19:41,379] [INFO] [config.py:734:__init__] Config mesh_device None world_size = 4\n",
      "[2025-05-18 11:19:41,555] [INFO] [config.py:734:__init__] Config mesh_device None world_size = 4\n",
      "[2025-05-18 11:19:41,566] [INFO] [config.py:734:__init__] Config mesh_device None world_size = 4\n",
      "256\n",
      "[2025-05-18 11:19:41,618] [INFO] [logging.py:107:log_dist] [Rank 0] DeepSpeed info: version=0.16.5, git-hash=unknown, git-branch=unknown\n",
      "[2025-05-18 11:19:41,618] [INFO] [config.py:734:__init__] Config mesh_device None world_size = 4\n",
      "[rank0]: Traceback (most recent call last):\n",
      "[rank0]:   File \"/kaggle/working/TimeZero/src/open_r1/grpo_video.py\", line 317, in <module>\n",
      "[rank0]:     main(script_args, training_args, model_args)\n",
      "[rank0]:   File \"/kaggle/working/TimeZero/src/open_r1/grpo_video.py\", line 279, in main\n",
      "[rank0]:     trainer = trainer_cls(\n",
      "[rank0]:   File \"/kaggle/working/TimeZero/src/open_r1/trainer/grpo_trainer_video.py\", line 367, in __init__\n",
      "[rank0]:     self.ref_model = prepare_deepspeed(self.ref_model, self.accelerator)\n",
      "[rank0]:   File \"/opt/conda/lib/python3.10/site-packages/trl/models/utils.py\", line 254, in prepare_deepspeed\n",
      "[rank0]:     model, *_ = deepspeed.initialize(model=model, config=config_kwargs)\n",
      "[rank0]:   File \"/opt/conda/lib/python3.10/site-packages/deepspeed/__init__.py\", line 193, in initialize\n",
      "[rank0]:     engine = DeepSpeedEngine(args=args,\n",
      "[rank0]:   File \"/opt/conda/lib/python3.10/site-packages/deepspeed/runtime/engine.py\", line 273, in __init__\n",
      "[rank0]:     self._configure_distributed_model(model)\n",
      "[rank0]:   File \"/opt/conda/lib/python3.10/site-packages/deepspeed/runtime/engine.py\", line 1287, in _configure_distributed_model\n",
      "[rank0]:     self._broadcast_model()\n",
      "[rank0]:   File \"/opt/conda/lib/python3.10/site-packages/deepspeed/runtime/engine.py\", line 1205, in _broadcast_model\n",
      "[rank0]:     dist.broadcast(p.data, groups._get_broadcast_src_rank(), group=self.seq_data_parallel_group)\n",
      "[rank0]:   File \"/opt/conda/lib/python3.10/site-packages/deepspeed/comm/comm.py\", line 117, in log_wrapper\n",
      "[rank0]:     return func(*args, **kwargs)\n",
      "[rank0]:   File \"/opt/conda/lib/python3.10/site-packages/deepspeed/comm/comm.py\", line 224, in broadcast\n",
      "[rank0]:     return cdb.broadcast(tensor=tensor, src=src, group=group, async_op=async_op)\n",
      "[rank0]:   File \"/opt/conda/lib/python3.10/site-packages/deepspeed/comm/torch.py\", line 206, in broadcast\n",
      "[rank0]:     return torch.distributed.broadcast(tensor=tensor, src=src, group=group, async_op=async_op)\n",
      "[rank0]:   File \"/opt/conda/lib/python3.10/site-packages/torch/distributed/c10d_logger.py\", line 81, in wrapper\n",
      "[rank0]:     return func(*args, **kwargs)\n",
      "[rank0]:   File \"/opt/conda/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py\", line 2726, in broadcast\n",
      "[rank0]:     work = group.broadcast([tensor], opts)\n",
      "[rank0]:   File \"/opt/conda/lib/python3.10/site-packages/torch/_compile.py\", line 32, in inner\n",
      "[rank0]:     return disable_fn(*args, **kwargs)\n",
      "[rank0]:   File \"/opt/conda/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py\", line 745, in _fn\n",
      "[rank0]:     return fn(*args, **kwargs)\n",
      "[rank0]:   File \"/opt/conda/lib/python3.10/site-packages/torch/distributed/tensor/_api.py\", line 346, in __torch_dispatch__\n",
      "[rank0]:     return DTensor._op_dispatcher.dispatch(\n",
      "[rank0]:   File \"/opt/conda/lib/python3.10/site-packages/torch/distributed/tensor/_dispatch.py\", line 167, in dispatch\n",
      "[rank0]:     op_info = self.unwrap_to_op_info(op_call, args, kwargs)\n",
      "[rank0]:   File \"/opt/conda/lib/python3.10/site-packages/torch/distributed/tensor/_dispatch.py\", line 400, in unwrap_to_op_info\n",
      "[rank0]:     assert mesh is not None, f\"found no DeviceMesh from dtensor args for {op_call}!\"\n",
      "[rank0]: AssertionError: found no DeviceMesh from dtensor args for c10d.broadcast_.default!\n",
      "[rank0]:[W518 11:19:43.729758648 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n",
      "W0518 11:19:45.205000 911 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 1007 closing signal SIGTERM\n",
      "W0518 11:19:45.206000 911 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 1008 closing signal SIGTERM\n",
      "W0518 11:19:45.206000 911 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 1010 closing signal SIGTERM\n",
      "E0518 11:19:45.320000 911 site-packages/torch/distributed/elastic/multiprocessing/api.py:869] failed (exitcode: 1) local_rank: 2 (pid: 1009) of binary: /opt/conda/bin/python3.10\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/bin/accelerate\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/accelerate/commands/accelerate_cli.py\", line 48, in main\n",
      "    args.func(args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/accelerate/commands/launch.py\", line 1165, in launch_command\n",
      "    multi_gpu_launcher(args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/accelerate/commands/launch.py\", line 799, in multi_gpu_launcher\n",
      "    distrib_run.run(args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/distributed/run.py\", line 909, in run\n",
      "    elastic_launch(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 138, in __call__\n",
      "    return launch_agent(self._config, self._entrypoint, list(args))\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 269, in launch_agent\n",
      "    raise ChildFailedError(\n",
      "torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \n",
      "============================================================\n",
      "src/open_r1/grpo_video.py FAILED\n",
      "------------------------------------------------------------\n",
      "Failures:\n",
      "  <NO_OTHER_FAILURES>\n",
      "------------------------------------------------------------\n",
      "Root Cause (first observed failure):\n",
      "[0]:\n",
      "  time      : 2025-05-18_11:19:45\n",
      "  host      : 2a3b92407841\n",
      "  rank      : 2 (local_rank: 2)\n",
      "  exitcode  : 1 (pid: 1009)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# !git pull\n",
    "!bash scripts/run_grpo_video.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/TimeZero\n"
     ]
    }
   ],
   "source": [
    "%cd TimeZero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
      "  pid, fd = os.forkpty()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already up to date.\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "[2025-05-17 10:22:42,711] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2025-05-17 10:22:42,711] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2025-05-17 10:22:42,711] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "[2025-05-17 10:22:42,711] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "df: df: /root/.triton/autotunedf: /root/.triton/autotunedf: /root/.triton/autotune: No such file or directory: No such file or directory/root/.triton/autotune: No such file or directory\n",
      "\n",
      ": No such file or directory\n",
      "\n",
      "INFO 05-17 10:22:47 [importing.py:53] Triton module has been replaced with a placeholder.\n",
      "INFO 05-17 10:22:47 [importing.py:53] Triton module has been replaced with a placeholder.\n",
      "INFO 05-17 10:22:47 [importing.py:53] Triton module has been replaced with a placeholder.\n",
      "INFO 05-17 10:22:47 [importing.py:53] Triton module has been replaced with a placeholder.\n",
      "INFO 05-17 10:22:47 [__init__.py:239] Automatically detected platform cuda.\n",
      "INFO 05-17 10:22:47 [__init__.py:239] Automatically detected platform cuda.\n",
      "INFO 05-17 10:22:47 [__init__.py:239] Automatically detected platform cuda.\n",
      "INFO 05-17 10:22:47 [__init__.py:239] Automatically detected platform cuda.\n",
      "[2025-05-17 10:22:49,951] [INFO] [comm.py:658:init_distributed] cdb=None\n",
      "[2025-05-17 10:22:49,951] [INFO] [comm.py:658:init_distributed] cdb=None\n",
      "[2025-05-17 10:22:49,951] [INFO] [comm.py:658:init_distributed] cdb=None\n",
      "[2025-05-17 10:22:49,951] [INFO] [comm.py:658:init_distributed] cdb=None\n",
      "[2025-05-17 10:22:49,951] [INFO] [comm.py:689:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "[rank0]: Traceback (most recent call last):\n",
      "[rank0]:   File \"/kaggle/working/TimeZero/src/open_r1/grpo_video.py\", line 317, in <module>\n",
      "[rank0]:     main(script_args, training_args, model_args)\n",
      "[rank0]:   File \"/kaggle/working/TimeZero/src/open_r1/grpo_video.py\", line 231, in main\n",
      "[rank0]:     dataset = load_json_dataset(\n",
      "[rank0]:   File \"/kaggle/working/TimeZero/src/open_r1/grpo_video.py\", line 177, in load_json_dataset\n",
      "[rank0]:     processor = AutoProcessor.from_pretrained(\n",
      "[rank0]:   File \"/opt/conda/lib/python3.10/site-packages/transformers/models/auto/processing_auto.py\", line 347, in from_pretrained\n",
      "[rank0]:     return processor_class.from_pretrained(\n",
      "[rank0]:   File \"/opt/conda/lib/python3.10/site-packages/transformers/processing_utils.py\", line 1079, in from_pretrained\n",
      "[rank0]:     args = cls._get_arguments_from_pretrained(pretrained_model_name_or_path, **kwargs)\n",
      "[rank0]:   File \"/opt/conda/lib/python3.10/site-packages/transformers/processing_utils.py\", line 1143, in _get_arguments_from_pretrained\n",
      "[rank0]:     args.append(attribute_class.from_pretrained(pretrained_model_name_or_path, **kwargs))\n",
      "[rank0]:   File \"/opt/conda/lib/python3.10/site-packages/transformers/models/auto/image_processing_auto.py\", line 579, in from_pretrained\n",
      "[rank0]:     raise ValueError(\n",
      "[rank0]: ValueError: Unrecognized image processor in /kaggle/input/qwen2.5-vl/transformers/3b-instruct/2. Should have a `image_processor_type` key in its preprocessor_config.json of config.json, or one of the following `model_type` keys in its config.json: align, aria, beit, bit, blip, blip-2, bridgetower, chameleon, chinese_clip, clip, clipseg, conditional_detr, convnext, convnextv2, cvt, data2vec-vision, deformable_detr, deit, depth_anything, depth_pro, deta, detr, dinat, dinov2, donut-swin, dpt, efficientformer, efficientnet, flava, focalnet, fuyu, gemma3, git, glpn, got_ocr2, grounding-dino, groupvit, hiera, idefics, idefics2, idefics3, ijepa, imagegpt, instructblip, instructblipvideo, kosmos-2, layoutlmv2, layoutlmv3, levit, llama4, llava, llava_next, llava_next_video, llava_onevision, mask2former, maskformer, mgp-str, mistral3, mllama, mobilenet_v1, mobilenet_v2, mobilevit, mobilevitv2, nat, nougat, oneformer, owlv2, owlvit, paligemma, perceiver, phi4_multimodal, pix2struct, pixtral, poolformer, prompt_depth_anything, pvt, pvt_v2, qwen2_5_vl, qwen2_vl, regnet, resnet, rt_detr, sam, segformer, seggpt, shieldgemma2, siglip, siglip2, superglue, swiftformer, swin, swin2sr, swinv2, table-transformer, timesformer, timm_wrapper, tvlt, tvp, udop, upernet, van, videomae, vilt, vipllava, vit, vit_hybrid, vit_mae, vit_msn, vitmatte, xclip, yolos, zoedepth\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "[rank1]: Traceback (most recent call last):\n",
      "[rank1]:   File \"/kaggle/working/TimeZero/src/open_r1/grpo_video.py\", line 317, in <module>\n",
      "[rank1]:     main(script_args, training_args, model_args)\n",
      "[rank1]:   File \"/kaggle/working/TimeZero/src/open_r1/grpo_video.py\", line 231, in main\n",
      "[rank1]:     dataset = load_json_dataset(\n",
      "[rank1]:   File \"/kaggle/working/TimeZero/src/open_r1/grpo_video.py\", line 177, in load_json_dataset\n",
      "[rank1]:     processor = AutoProcessor.from_pretrained(\n",
      "[rank1]:   File \"/opt/conda/lib/python3.10/site-packages/transformers/models/auto/processing_auto.py\", line 347, in from_pretrained\n",
      "[rank1]:     return processor_class.from_pretrained(\n",
      "[rank1]:   File \"/opt/conda/lib/python3.10/site-packages/transformers/processing_utils.py\", line 1079, in from_pretrained\n",
      "[rank1]:     args = cls._get_arguments_from_pretrained(pretrained_model_name_or_path, **kwargs)\n",
      "[rank1]:   File \"/opt/conda/lib/python3.10/site-packages/transformers/processing_utils.py\", line 1143, in _get_arguments_from_pretrained\n",
      "[rank1]:     args.append(attribute_class.from_pretrained(pretrained_model_name_or_path, **kwargs))\n",
      "[rank1]:   File \"/opt/conda/lib/python3.10/site-packages/transformers/models/auto/image_processing_auto.py\", line 579, in from_pretrained\n",
      "[rank1]:     raise ValueError(\n",
      "[rank1]: ValueError: Unrecognized image processor in /kaggle/input/qwen2.5-vl/transformers/3b-instruct/2. Should have a `image_processor_type` key in its preprocessor_config.json of config.json, or one of the following `model_type` keys in its config.json: align, aria, beit, bit, blip, blip-2, bridgetower, chameleon, chinese_clip, clip, clipseg, conditional_detr, convnext, convnextv2, cvt, data2vec-vision, deformable_detr, deit, depth_anything, depth_pro, deta, detr, dinat, dinov2, donut-swin, dpt, efficientformer, efficientnet, flava, focalnet, fuyu, gemma3, git, glpn, got_ocr2, grounding-dino, groupvit, hiera, idefics, idefics2, idefics3, ijepa, imagegpt, instructblip, instructblipvideo, kosmos-2, layoutlmv2, layoutlmv3, levit, llama4, llava, llava_next, llava_next_video, llava_onevision, mask2former, maskformer, mgp-str, mistral3, mllama, mobilenet_v1, mobilenet_v2, mobilevit, mobilevitv2, nat, nougat, oneformer, owlv2, owlvit, paligemma, perceiver, phi4_multimodal, pix2struct, pixtral, poolformer, prompt_depth_anything, pvt, pvt_v2, qwen2_5_vl, qwen2_vl, regnet, resnet, rt_detr, sam, segformer, seggpt, shieldgemma2, siglip, siglip2, superglue, swiftformer, swin, swin2sr, swinv2, table-transformer, timesformer, timm_wrapper, tvlt, tvp, udop, upernet, van, videomae, vilt, vipllava, vit, vit_hybrid, vit_mae, vit_msn, vitmatte, xclip, yolos, zoedepth\n",
      "[rank3]: Traceback (most recent call last):\n",
      "[rank3]:   File \"/kaggle/working/TimeZero/src/open_r1/grpo_video.py\", line 317, in <module>\n",
      "[rank3]:     main(script_args, training_args, model_args)\n",
      "[rank3]:   File \"/kaggle/working/TimeZero/src/open_r1/grpo_video.py\", line 231, in main\n",
      "[rank3]:     dataset = load_json_dataset(\n",
      "[rank3]:   File \"/kaggle/working/TimeZero/src/open_r1/grpo_video.py\", line 177, in load_json_dataset\n",
      "[rank3]:     processor = AutoProcessor.from_pretrained(\n",
      "[rank3]:   File \"/opt/conda/lib/python3.10/site-packages/transformers/models/auto/processing_auto.py\", line 347, in from_pretrained\n",
      "[rank3]:     return processor_class.from_pretrained(\n",
      "[rank3]:   File \"/opt/conda/lib/python3.10/site-packages/transformers/processing_utils.py\", line 1079, in from_pretrained\n",
      "[rank3]:     args = cls._get_arguments_from_pretrained(pretrained_model_name_or_path, **kwargs)\n",
      "[rank3]:   File \"/opt/conda/lib/python3.10/site-packages/transformers/processing_utils.py\", line 1143, in _get_arguments_from_pretrained\n",
      "[rank3]:     args.append(attribute_class.from_pretrained(pretrained_model_name_or_path, **kwargs))\n",
      "[rank3]:   File \"/opt/conda/lib/python3.10/site-packages/transformers/models/auto/image_processing_auto.py\", line 579, in from_pretrained\n",
      "[rank3]:     raise ValueError(\n",
      "[rank3]: ValueError: Unrecognized image processor in /kaggle/input/qwen2.5-vl/transformers/3b-instruct/2. Should have a `image_processor_type` key in its preprocessor_config.json of config.json, or one of the following `model_type` keys in its config.json: align, aria, beit, bit, blip, blip-2, bridgetower, chameleon, chinese_clip, clip, clipseg, conditional_detr, convnext, convnextv2, cvt, data2vec-vision, deformable_detr, deit, depth_anything, depth_pro, deta, detr, dinat, dinov2, donut-swin, dpt, efficientformer, efficientnet, flava, focalnet, fuyu, gemma3, git, glpn, got_ocr2, grounding-dino, groupvit, hiera, idefics, idefics2, idefics3, ijepa, imagegpt, instructblip, instructblipvideo, kosmos-2, layoutlmv2, layoutlmv3, levit, llama4, llava, llava_next, llava_next_video, llava_onevision, mask2former, maskformer, mgp-str, mistral3, mllama, mobilenet_v1, mobilenet_v2, mobilevit, mobilevitv2, nat, nougat, oneformer, owlv2, owlvit, paligemma, perceiver, phi4_multimodal, pix2struct, pixtral, poolformer, prompt_depth_anything, pvt, pvt_v2, qwen2_5_vl, qwen2_vl, regnet, resnet, rt_detr, sam, segformer, seggpt, shieldgemma2, siglip, siglip2, superglue, swiftformer, swin, swin2sr, swinv2, table-transformer, timesformer, timm_wrapper, tvlt, tvp, udop, upernet, van, videomae, vilt, vipllava, vit, vit_hybrid, vit_mae, vit_msn, vitmatte, xclip, yolos, zoedepth\n",
      "[rank2]: Traceback (most recent call last):\n",
      "[rank2]:   File \"/kaggle/working/TimeZero/src/open_r1/grpo_video.py\", line 317, in <module>\n",
      "[rank2]:     main(script_args, training_args, model_args)\n",
      "[rank2]:   File \"/kaggle/working/TimeZero/src/open_r1/grpo_video.py\", line 231, in main\n",
      "[rank2]:     dataset = load_json_dataset(\n",
      "[rank2]:   File \"/kaggle/working/TimeZero/src/open_r1/grpo_video.py\", line 177, in load_json_dataset\n",
      "[rank2]:     processor = AutoProcessor.from_pretrained(\n",
      "[rank2]:   File \"/opt/conda/lib/python3.10/site-packages/transformers/models/auto/processing_auto.py\", line 347, in from_pretrained\n",
      "[rank2]:     return processor_class.from_pretrained(\n",
      "[rank2]:   File \"/opt/conda/lib/python3.10/site-packages/transformers/processing_utils.py\", line 1079, in from_pretrained\n",
      "[rank2]:     args = cls._get_arguments_from_pretrained(pretrained_model_name_or_path, **kwargs)\n",
      "[rank2]:   File \"/opt/conda/lib/python3.10/site-packages/transformers/processing_utils.py\", line 1143, in _get_arguments_from_pretrained\n",
      "[rank2]:     args.append(attribute_class.from_pretrained(pretrained_model_name_or_path, **kwargs))\n",
      "[rank2]:   File \"/opt/conda/lib/python3.10/site-packages/transformers/models/auto/image_processing_auto.py\", line 579, in from_pretrained\n",
      "[rank2]:     raise ValueError(\n",
      "[rank2]: ValueError: Unrecognized image processor in /kaggle/input/qwen2.5-vl/transformers/3b-instruct/2. Should have a `image_processor_type` key in its preprocessor_config.json of config.json, or one of the following `model_type` keys in its config.json: align, aria, beit, bit, blip, blip-2, bridgetower, chameleon, chinese_clip, clip, clipseg, conditional_detr, convnext, convnextv2, cvt, data2vec-vision, deformable_detr, deit, depth_anything, depth_pro, deta, detr, dinat, dinov2, donut-swin, dpt, efficientformer, efficientnet, flava, focalnet, fuyu, gemma3, git, glpn, got_ocr2, grounding-dino, groupvit, hiera, idefics, idefics2, idefics3, ijepa, imagegpt, instructblip, instructblipvideo, kosmos-2, layoutlmv2, layoutlmv3, levit, llama4, llava, llava_next, llava_next_video, llava_onevision, mask2former, maskformer, mgp-str, mistral3, mllama, mobilenet_v1, mobilenet_v2, mobilevit, mobilevitv2, nat, nougat, oneformer, owlv2, owlvit, paligemma, perceiver, phi4_multimodal, pix2struct, pixtral, poolformer, prompt_depth_anything, pvt, pvt_v2, qwen2_5_vl, qwen2_vl, regnet, resnet, rt_detr, sam, segformer, seggpt, shieldgemma2, siglip, siglip2, superglue, swiftformer, swin, swin2sr, swinv2, table-transformer, timesformer, timm_wrapper, tvlt, tvp, udop, upernet, van, videomae, vilt, vipllava, vit, vit_hybrid, vit_mae, vit_msn, vitmatte, xclip, yolos, zoedepth\n",
      "[rank0]:[W517 10:22:51.432706327 ProcessGroupNCCL.cpp:1496] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())\n",
      "W0517 10:22:52.901000 1220 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 1317 closing signal SIGTERM\n",
      "W0517 10:22:52.901000 1220 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 1318 closing signal SIGTERM\n",
      "W0517 10:22:52.901000 1220 site-packages/torch/distributed/elastic/multiprocessing/api.py:897] Sending process 1319 closing signal SIGTERM\n",
      "E0517 10:22:52.997000 1220 site-packages/torch/distributed/elastic/multiprocessing/api.py:869] failed (exitcode: 1) local_rank: 0 (pid: 1316) of binary: /opt/conda/bin/python3.10\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/bin/accelerate\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/accelerate/commands/accelerate_cli.py\", line 48, in main\n",
      "    args.func(args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/accelerate/commands/launch.py\", line 1165, in launch_command\n",
      "    multi_gpu_launcher(args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/accelerate/commands/launch.py\", line 799, in multi_gpu_launcher\n",
      "    distrib_run.run(args)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/distributed/run.py\", line 909, in run\n",
      "    elastic_launch(\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 138, in __call__\n",
      "    return launch_agent(self._config, self._entrypoint, list(args))\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 269, in launch_agent\n",
      "    raise ChildFailedError(\n",
      "torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \n",
      "============================================================\n",
      "src/open_r1/grpo_video.py FAILED\n",
      "------------------------------------------------------------\n",
      "Failures:\n",
      "  <NO_OTHER_FAILURES>\n",
      "------------------------------------------------------------\n",
      "Root Cause (first observed failure):\n",
      "[0]:\n",
      "  time      : 2025-05-17_10:22:52\n",
      "  host      : 4131460c6668\n",
      "  rank      : 0 (local_rank: 0)\n",
      "  exitcode  : 1 (pid: 1316)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "!git pull\n",
    "!bash scripts/run_grpo_video.sh"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
